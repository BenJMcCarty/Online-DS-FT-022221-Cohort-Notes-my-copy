{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 37: Intro to Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 05/27/21\n",
    "- onl01-dtsc-ft-022221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learn how to load in timeseries data into pandas\n",
    "- Learn how to plot timeseries in pandas\n",
    "- Learn how to resample at different time frequencies\n",
    "- Learn about types of time series trends and how to remove them.\n",
    "- Learn about seasonal decomposition\n",
    "\n",
    "- Prepare a time series dataset to use for modeling next class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas Timeseries Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)\n",
    "- ['Timeseries Offset Aliases'](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "- [Anchored Offsets](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets)\n",
    "\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:20.251212Z",
     "start_time": "2021-05-27T15:20:19.130658Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import the essentials\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "\n",
    "\n",
    "## Setting figures to timeseries-friendly\n",
    "mpl.rcParams['figure.figsize'] = (12,4)\n",
    "# sns.set_context('talk')\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "## Time Series Tools from statsmodels\n",
    "import statsmodels.tsa.api as tsa\n",
    "import statsmodels\n",
    "print(f'Statsmodels version = {statsmodels.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Time Series from a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is from Baltimore's Open-Data Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- New Crime Stats Just downloaded:\n",
    "- [Baltimore Open Data](https://www.baltimorepolice.org/crime-stats/open-data)\n",
    "    - We Are Using [Part 1 Crime](https://data.baltimorecity.gov/search?q=crime%20data):\n",
    "    - https://data.baltimorecity.gov/datasets/3eeb0a2cbae94b3e8549a8193717a9e1_0/explore\n",
    "    \n",
    "- **Note: to save space, I converted the .csv to a .csv.gz using this code**\n",
    "```python \n",
    "## Read orig csv from Downloads and save .gz vers to local folder\n",
    "df = pd.read_csv('/Users/jamesirving/Downloads/Part1_Crime_data.csv')\n",
    "df.to_csv('baltimore_crime_05-26-21.csv.gz',compression='gzip',index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:21.514792Z",
     "start_time": "2021-05-27T15:20:20.253270Z"
    }
   },
   "outputs": [],
   "source": [
    "## Read in the data\n",
    "file = 'baltimore_crime_05-26-21.csv.gz'\n",
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:21.544014Z",
     "start_time": "2021-05-27T15:20:21.517323Z"
    }
   },
   "outputs": [],
   "source": [
    "## Keeping Necessary/Desired Columns\n",
    "keep_cols = ['CrimeDateTime','Description','Total_Incidents',\n",
    "             'District','Neighborhood'\n",
    "#               'Weapon', 'Latitude','Longitude',\n",
    "            ]\n",
    "df = df[keep_cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Time Series Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index must be a `datetimeindex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:21.550279Z",
     "start_time": "2021-05-27T15:20:21.546787Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check Index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:21.707641Z",
     "start_time": "2021-05-27T15:20:21.552410Z"
    }
   },
   "outputs": [],
   "source": [
    "## Convert CrimeDateTime to datetime and set as index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we notice about the index?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- frequency?\n",
    "- range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.075948Z",
     "start_time": "2021-05-27T15:20:21.710028Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspect the value_counts for the different types of crimes\n",
    "\n",
    "# display with an inline-barplot inside your df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.114031Z",
     "start_time": "2021-05-27T15:20:22.077842Z"
    }
   },
   "outputs": [],
   "source": [
    "## Grab All Shootings  - using groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.122373Z",
     "start_time": "2021-05-27T15:20:22.117897Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking total-incidents value_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.158383Z",
     "start_time": "2021-05-27T15:20:22.125863Z"
    }
   },
   "outputs": [],
   "source": [
    "## Lets get just Shootings in a new series\n",
    "\n",
    "# Make a crime var with the name of the crime we want\n",
    "\n",
    "## save ts from Total Incidents and rename series to crime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.184789Z",
     "start_time": "2021-05-27T15:20:22.160757Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get list of crimes to iterate through\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.584275Z",
     "start_time": "2021-05-27T15:20:22.186749Z"
    }
   },
   "outputs": [],
   "source": [
    "## make a dict of all crime types' DataFrames \n",
    "\n",
    "## For each crime type\n",
    "    \n",
    "    ## Get the group df\n",
    "    \n",
    "    ## Save the group_df into the CRIMES dict\n",
    "    \n",
    "## Display the keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.590598Z",
     "start_time": "2021-05-27T15:20:22.586024Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pull out shooting from CRIMES dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.765655Z",
     "start_time": "2021-05-27T15:20:22.592445Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot the ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What went wrong? What are we looking at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Frequencies & Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.778241Z",
     "start_time": "2021-05-27T15:20:22.767689Z"
    }
   },
   "outputs": [],
   "source": [
    "## Resample to daily data (\"D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:22.784594Z",
     "start_time": "2021-05-27T15:20:22.780240Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the index, whats different?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:23.039087Z",
     "start_time": "2021-05-27T15:20:22.786422Z"
    }
   },
   "outputs": [],
   "source": [
    "## PLot the time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Q: It worked! But whats the issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing With Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure your index is sorted first'\n",
    "- Use `.loc` with dates as strings for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:23.250220Z",
     "start_time": "2021-05-27T15:20:23.040719Z"
    }
   },
   "outputs": [],
   "source": [
    "## Slice out dates prior to rise in daily counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Much better! sort of... but whats the issue now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series Frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want the daily counts for our crimes.\n",
    "    - In order to do so we have to resample the ts using the correct frequency alias.\n",
    "- For time series modeling, we will need our time series as a specific frequency without missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Frequency Aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "\n",
    "\n",
    "|Alias\t| Description|\n",
    "| --- | --- |\n",
    "|B |\tbusiness day frequency|\n",
    "|C |\tcustom business day frequency|\n",
    "|D |\tcalendar day frequency|\n",
    "|W |\tweekly frequency|\n",
    "|M |\tmonth end frequency|\n",
    "|SM |\tsemi-month end frequency (15th and end of month)|\n",
    "|BM |\tbusiness month end frequency|\n",
    "|CBM |\tcustom business month end frequency|\n",
    "|MS |\tmonth start frequency|\n",
    "|SMS |\tsemi-month start frequency (1st and 15th)|\n",
    "|BMS |\tbusiness month start frequency|\n",
    "|CBMS |\tcustom business month start frequency|\n",
    "|Q |\tquarter end frequency|\n",
    "|BQ |\tbusiness quarter end frequency|\n",
    "|QS |\tquarter start frequency|\n",
    "|BQS |\tbusiness quarter start frequency|\n",
    "|A, Y |\tyear end frequency|\n",
    "|BA, BY |\tbusiness year end frequency|\n",
    "|AS, YS |\tyear start frequency|\n",
    "|BAS, BYS |\tbusiness year start frequency|\n",
    "|BH | business hour frequency|\n",
    "|H | hourly frequency|\n",
    "|T |  min\tminutely frequency|\n",
    "|S | secondly frequency|\n",
    "|L |  ms\tmilliseconds|\n",
    "|U |  us\tmicroseconds|\n",
    "|N | nanoseconds|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Resampled ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:24.269361Z",
     "start_time": "2021-05-27T15:20:23.252050Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the same ts as different frequencies\n",
    "## Specify freq codes daily, every 3 days, weekly, Monthly, Quarterly, yearly\n",
    "\n",
    "## select ts from CRIMES\n",
    "\n",
    "## For each freq code\n",
    "    \n",
    "    ## make a new figure, resample and plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:24.605118Z",
     "start_time": "2021-05-27T15:20:24.271037Z"
    }
   },
   "outputs": [],
   "source": [
    "## Repeat the above loop,but plot it all on one figure\n",
    "\n",
    "## Specify freq codes\n",
    "\n",
    "## select ts from CRIMES\n",
    "\n",
    "## For each freq code, resample and plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize all CRIMES as \"D\" Freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- **Loop through all CRIMES, slice out 2015-Present, and resample as \"D\"**\n",
    "    - We can always downsample without issue, but upsampling is a problematic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dictionaries for TIme Series preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:24.683601Z",
     "start_time": "2021-05-27T15:20:24.606725Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save all crimes from 2015 on with freq=D in new TS dict\n",
    "\n",
    "## For each crime\n",
    "    \n",
    "    ## Resample and slice and save ts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:24.690931Z",
     "start_time": "2021-05-27T15:20:24.685560Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check shooting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the same frequency for each crime series, make them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:24.712334Z",
     "start_time": "2021-05-27T15:20:24.693055Z"
    }
   },
   "outputs": [],
   "source": [
    "## Concatenate all ts together into one ts_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize all ts with the differnet requency codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.534837Z",
     "start_time": "2021-05-27T15:20:24.718178Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the same ts as different frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.544228Z",
     "start_time": "2021-05-27T15:20:26.538708Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check For Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.560549Z",
     "start_time": "2021-05-27T15:20:26.546199Z"
    }
   },
   "outputs": [],
   "source": [
    "# save a T/F index for if a row has any nulls\n",
    "\n",
    "# check out the null rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: what do we notice about our null values? Where are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - We have several options for filling in null values for time series, based on what would be best for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.576761Z",
     "start_time": "2021-05-27T15:20:26.562566Z"
    }
   },
   "outputs": [],
   "source": [
    "## FFill null values with the next non-null value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.593328Z",
     "start_time": "2021-05-27T15:20:26.578724Z"
    }
   },
   "outputs": [],
   "source": [
    "## FFill null values with the previous non-null value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.601883Z",
     "start_time": "2021-05-27T15:20:26.595827Z"
    }
   },
   "outputs": [],
   "source": [
    "## We have crime counts, so it makes sense to fill with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.637273Z",
     "start_time": "2021-05-27T15:20:26.604475Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save df to csv for time series modeling next class\n",
    "# ts_df.to_csv('baltimore_crime_counts_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-removing-trends-online-ds-ft-100719/master/images/new_trendseasonal.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:2em\">Mean</div>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_mean_nonstationary.png\" width=70%>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;font-size:3em\">Variance</div>\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_cov_nonstationary.png\" width=70%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.853407Z",
     "start_time": "2021-05-27T15:20:26.639237Z"
    }
   },
   "outputs": [],
   "source": [
    "## Grab ROBBERY - STREET and resample as weekly data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dickey Fuller Test for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:26.939886Z",
     "start_time": "2021-05-27T15:20:26.855721Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Lab Function\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adfuller_test_df(ts,index=['AD Fuller Results']):\n",
    "    \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "    that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    \n",
    "    df_res = tsa.stattools.adfuller(ts)\n",
    "    \n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,df_res[:4]))\n",
    "    \n",
    "    res['p<.05'] = res['p-value']<.05\n",
    "    res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "    if isinstance(index,str):\n",
    "        index = [index]\n",
    "    res_df = pd.DataFrame(res,index=index)\n",
    "    res_df = res_df[['Test Statistic','#Lags Used',\n",
    "                     '# of Observations Used','p-value','p<.05',\n",
    "                    'Stationary?']]\n",
    "    return res_df\n",
    "\n",
    "\n",
    "\n",
    "def stationarity_check(TS,window=8,plot=True,index=['AD Fuller Results']):\n",
    "    \"\"\"Adapted from https://github.com/learn-co-curriculum/dsc-removing-trends-lab/tree/solution\"\"\"\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    roll_mean = TS.rolling(window=window, center=False).mean()\n",
    "    roll_std = TS.rolling(window=window, center=False).std()\n",
    "    \n",
    "    # Perform the Dickey Fuller Test\n",
    "    dftest = adfuller_test_df(TS,index=index)\n",
    "    \n",
    "    if plot:\n",
    "        # Plot rolling statistics:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        plt.plot(TS, color='blue',label=f'Original (freq={TS.index.freq})')\n",
    "        plt.plot(roll_mean, color='red', label=f'Rolling Mean (window={window})')\n",
    "        plt.plot(roll_std, color='black', label = f'Rolling Std (window={window})')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "        display(dftest)\n",
    "        plt.show(block=False)\n",
    "        \n",
    "    return dftest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:27.179634Z",
     "start_time": "2021-05-27T15:20:26.942233Z"
    }
   },
   "outputs": [],
   "source": [
    "## Test stationariy check function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For time series modeling, we will want to get our time series stationary.*\n",
    "\n",
    "#### Trend Removal Methods\n",
    "- Differencing (`.diff()`)\n",
    "- Log-Transformation (`np.log`)\n",
    "- Subtract Rolling Mean (`ts-ts.rolling().mean()`)\n",
    "- Subtract Exponentially-Weighted Mean (`ts-ts.ewm().mean()`)\n",
    "- Seasonal Decomposition (`from statsmodels.tsa.seasonal import seasonal_decompose`\n",
    ")\n",
    "\n",
    "_`*`=caveat to be discussed tomorrow_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:27.615398Z",
     "start_time": "2021-05-27T15:20:27.181415Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot Original Time Series and Check for Stationarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:27.824412Z",
     "start_time": "2021-05-27T15:20:27.616947Z"
    }
   },
   "outputs": [],
   "source": [
    "## Apply differnncing, plot and get adfuller test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.016177Z",
     "start_time": "2021-05-27T15:20:27.826511Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log Transform, plot and get adfuller test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.226626Z",
     "start_time": "2021-05-27T15:20:28.018073Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.419839Z",
     "start_time": "2021-05-27T15:20:28.228394Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Exponentially Weight Mean Rolling mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What do we notice? What methods achieved stationarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.911691Z",
     "start_time": "2021-05-27T15:20:28.421623Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use seasonal decompose on the ts and plot\n",
    "plt.rcParams['figure.figsize']=(12,6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking which components are stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.915676Z",
     "start_time": "2021-05-27T15:20:28.913396Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save seasonal/trend/resid in a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:20:28.978248Z",
     "start_time": "2021-05-27T15:20:28.917453Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Make a list of adfuller results to append\n",
    "\n",
    "## Save results of orig ts\n",
    "\n",
    "## Loop through decomp dict, \n",
    "\n",
    "    # Fill any missing values, get adfuller result\n",
    "\n",
    "    \n",
    "    ## Append res to decomp_stationary\n",
    "\n",
    "## make into a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:48:54.241164Z",
     "start_time": "2021-05-27T15:48:54.238473Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot decomp again for convenient comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tomorrow we will continue working with the dataset we processed today for time series modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Date Str Formatting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "Formatting follows the Python datetime <strong><a href='http://strftime.org/'>strftime</a></strong> codes.<br>\n",
    "The following examples are based on <tt>datetime.datetime(2001, 2, 3, 16, 5, 6)</tt>:\n",
    "<br><br>\n",
    "\n",
    "<table style=\"display: inline-block\">  \n",
    "<tr><th>CODE</th><th>MEANING</th><th>EXAMPLE</th><tr>\n",
    "<tr><td>%Y</td><td>Year with century as a decimal number.</td><td>2001</td></tr>\n",
    "<tr><td>%y</td><td>Year without century as a zero-padded decimal number.</td><td>01</td></tr>\n",
    "<tr><td>%m</td><td>Month as a zero-padded decimal number.</td><td>02</td></tr>\n",
    "<tr><td>%B</td><td>Month as locale’s full name.</td><td>February</td></tr>\n",
    "<tr><td>%b</td><td>Month as locale’s abbreviated name.</td><td>Feb</td></tr>\n",
    "<tr><td>%d</td><td>Day of the month as a zero-padded decimal number.</td><td>03</td></tr>  \n",
    "<tr><td>%A</td><td>Weekday as locale’s full name.</td><td>Saturday</td></tr>\n",
    "<tr><td>%a</td><td>Weekday as locale’s abbreviated name.</td><td>Sat</td></tr>\n",
    "<tr><td>%H</td><td>Hour (24-hour clock) as a zero-padded decimal number.</td><td>16</td></tr>\n",
    "<tr><td>%I</td><td>Hour (12-hour clock) as a zero-padded decimal number.</td><td>04</td></tr>\n",
    "<tr><td>%p</td><td>Locale’s equivalent of either AM or PM.</td><td>PM</td></tr>\n",
    "<tr><td>%M</td><td>Minute as a zero-padded decimal number.</td><td>05</td></tr>\n",
    "<tr><td>%S</td><td>Second as a zero-padded decimal number.</td><td>06</td></tr>\n",
    "</table>\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>CODE</th><th>MEANING</th><th>EXAMPLE</th><tr>\n",
    "<tr><td>%#m</td><td>Month as a decimal number. (Windows)</td><td>2</td></tr>\n",
    "<tr><td>%-m</td><td>Month as a decimal number. (Mac/Linux)</td><td>2</td></tr>\n",
    "<tr><td>%#x</td><td>Long date</td><td>Saturday, February 03, 2001</td></tr>\n",
    "<tr><td>%#c</td><td>Long date and time</td><td>Saturday, February 03, 2001 16:05:06</td></tr>\n",
    "</table>  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Attempting Using Grouper like in lab, but not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:31:02.150917Z",
     "start_time": "2021-05-27T15:31:02.148970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ts_q = ts.to_frame()\n",
    "\n",
    "# ts_q#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:31:04.000491Z",
     "start_time": "2021-05-27T15:31:03.998537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " # Use pandas grouper to group values using annual frequency\n",
    "# year_groups = ts_q.groupby(pd.Grouper(freq ='A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:31:05.831500Z",
     "start_time": "2021-05-27T15:31:05.829615Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Create a new DataFrame and store yearly values in columns \n",
    "# ts_annual = pd.DataFrame()\n",
    "\n",
    "# for yr, group in year_groups:\n",
    "# #     display(group.values)\n",
    "# #     ts_annual[yr.year] = group.values.ravel()\n",
    "    \n",
    "# # Plot the yearly groups as subplots\n",
    "# # ts_annual.plot(figsize = (13,8), subplots=True, legend=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
