{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 38: Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 05/27/21\n",
    "- onl01-dtsc-ft-022221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "\n",
    "\n",
    "- Learn about PACF, ACF\n",
    "- Introduce ARIMA and SARIMA models.\n",
    "- Activity: SARIMA Models - Lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas Timeseries Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)\n",
    "- ['Timeseries Offset Aliases'](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "- [Anchored Offsets](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets)\n",
    "\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting Baltimore Crime from Yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.040437Z",
     "start_time": "2021-05-29T22:32:27.798671Z"
    }
   },
   "outputs": [],
   "source": [
    "# import fsds as fs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "from random import gauss\n",
    "\n",
    "pd.set_option('precision',3)\n",
    "plt.rcParams['figure.figsize'] = [12,5]\n",
    "\n",
    "import statsmodels.tsa.api as tsa\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.083797Z",
     "start_time": "2021-05-29T22:32:31.042462Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Functions from Last Class \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ts_functions as tsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.151742Z",
     "start_time": "2021-05-29T22:32:31.086565Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load in file and parse_dates, check index\n",
    "file = '../topic_37_intro_to_time_series/baltimore_crime_counts_2021.csv'\n",
    "df = pd.read_csv(file,parse_dates=True, index_col='CrimeDateTime')\n",
    "display(df.head(),df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - If data is already in the frequency desired, can use `.resample(\"D\").asfreq()` instead of an aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.204610Z",
     "start_time": "2021-05-29T22:32:31.154114Z"
    }
   },
   "outputs": [],
   "source": [
    "## resample.asfreq\n",
    "df = df.resample('D').asfreq()\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.257667Z",
     "start_time": "2021-05-29T22:32:31.206482Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get a list of crimes to remind ourselves what we have\n",
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:31.993244Z",
     "start_time": "2021-05-29T22:32:31.259460Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot the weekly dataset to identify which ts to model\n",
    "ax = df.plot(figsize=(12,8)) \n",
    "ax.legend(bbox_to_anchor=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For modeling purposes, we are going to focus on **Weekly crime** forecasts instead of daily, so we will resample to Weekly freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:32.047616Z",
     "start_time": "2021-05-29T22:32:31.995767Z"
    }
   },
   "outputs": [],
   "source": [
    "## Lets resample the df to Weekly and save as new dfw\n",
    "# also, let's take 2018 - present for ~3 years of data\n",
    "dfw = df.resample('W').sum().loc['2017':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:32.531398Z",
     "start_time": "2021-05-29T22:32:32.051791Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the weekly dataset to identify which ts to model\n",
    "ax = dfw.plot(figsize=(12,8)) \n",
    "ax.legend(bbox_to_anchor=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T15:00:53.733926Z",
     "start_time": "2021-05-28T15:00:52.686432Z"
    }
   },
   "source": [
    "> #### Theres a lot of lines to sift through so lets use plotly express to make it easier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:55:57.115561Z",
     "start_time": "2021-05-29T22:55:57.112923Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use px.line \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we dive into modeling crime, let's discuss the simplest time series models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Time Series models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- White Noise Model\n",
    "- Random Walk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise Model\n",
    "- 3 Properties:\n",
    "    - Fixed and constant mean\n",
    "    - Fixed and constant variance\n",
    "    - No correlation over time\n",
    "\n",
    "$$\\Large Y_t =  \\epsilon_t$$\n",
    "\n",
    "The error term is randomly distributed around the mean, has constant variance, and no autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gaussian White Noise: A special case of a White Noise model is \n",
    "    - Mean is equal to zero\n",
    "    - variance is equal to 1\n",
    "    $$\\large Y_t = \\epsilon_t + \\theta * \\epsilon_{t-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:33.214679Z",
     "start_time": "2021-05-29T22:32:33.029868Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## White noise has mean=0, variance =1\n",
    "mean = 0\n",
    "variance = 1\n",
    "\n",
    "## Make a white noise time series\n",
    "noise = pd.Series([gauss(mean, np.sqrt(variance)) for x in range(1000)])\n",
    "noise.plot(title='White Noise')\n",
    "\n",
    "## Check our mean and variance\n",
    "noise.mean(),noise.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify White Noise \n",
    "\n",
    "##### From 2015 scipy conference paper https://conference.scipy.org/proceedings/scipy2015/pdfs/margaret_mahan.pdf\n",
    "- Use windows of 10% to asses white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:33.263233Z",
     "start_time": "2021-05-29T22:32:33.216299Z"
    }
   },
   "outputs": [],
   "source": [
    "## Calc 10% of time steps/lags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:33.607622Z",
     "start_time": "2021-05-29T22:32:33.268377Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Check if white noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model\n",
    "- Two Properties:\n",
    "    - Has no specified mean or variance\n",
    "    - Has a strong dependence over time\n",
    "\n",
    "- Mathematically, this can be written as:\n",
    "\n",
    "$$\\large Y_t = Y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "- Where $\\epsilon_t$ is a *mean zero* white noise model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Walk with a Drift\":\n",
    "    - a drift parameter $c$, steering in a certain direction.\n",
    "$$\\large Y_t = c + Y_{t-1} + \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:33.814434Z",
     "start_time": "2021-05-29T22:32:33.609688Z"
    }
   },
   "outputs": [],
   "source": [
    "## Using white noise to simulate a random walk\n",
    "#https://campus.datacamp.com/courses/time-series-analysis-in-python/some-simple-time-series?ex=7\n",
    "walk = noise.shift(-1)+noise.cumsum()\n",
    "walk.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:34.161172Z",
     "start_time": "2021-05-29T22:32:33.816857Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check if random walk is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a random walk is differenced it returns a white noise. \n",
    "\n",
    "This is a result of the mathematical formula:\n",
    "\n",
    "$$Y_t = Y_{t-1} + \\epsilon_t$$\n",
    "which is equivalent to\n",
    "$$Y_t - Y_{t-1} = \\epsilon_t$$\n",
    "\n",
    "and we know that $\\epsilon_t$ is a mean-zero white noise process! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:34.506167Z",
     "start_time": "2021-05-29T22:32:34.163151Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirm walk differenced returns a white noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Basic Time Series in Baltimore Crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Crimes Optimal for Different Types of Times Series Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the plotly plot, explore individual crimes to identify which crimes are appropriate for the different types of time series models.\n",
    "- Then confirm using stationarity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- White Noise: ___\n",
    "- Random Walk: ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:57:31.610503Z",
     "start_time": "2021-05-29T22:57:31.519193Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## re-plot dfw and identify crimes that follow a white nosie or random walk model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:34.845846Z",
     "start_time": "2021-05-29T22:32:34.797995Z"
    }
   },
   "outputs": [],
   "source": [
    "### Identifying Crimes Optimal for Different Types of Times Series Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Our White Noise Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:35.102471Z",
     "start_time": "2021-05-29T22:32:34.847915Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualize white noise-like ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:35.463090Z",
     "start_time": "2021-05-29T22:32:35.104408Z"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate 10% window and check stationarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Our Random Walk Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:35.703420Z",
     "start_time": "2021-05-29T22:32:35.464897Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualize random-walk ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:36.181076Z",
     "start_time": "2021-05-29T22:32:35.761467Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check if our random walk is stationary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:36.571582Z",
     "start_time": "2021-05-29T22:32:36.188279Z"
    }
   },
   "outputs": [],
   "source": [
    "## confirm our random walk becomes stationary white noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation, Autocorrelation & Partial Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Time Series that are correlated with themselves (autocorrelation) are best suited for a more complex modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:36.907976Z",
     "start_time": "2021-05-29T22:32:36.634077Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use AGG. ASSAULT as ts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Autocorrelation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:37.145656Z",
     "start_time": "2021-05-29T22:32:36.909963Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use AGG. ASSAULT as ts and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:37.388792Z",
     "start_time": "2021-05-29T22:32:37.147626Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save differenced version and plot\n",
    "ts_diff = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:37.683383Z",
     "start_time": "2021-05-29T22:32:37.390928Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shift the ts_orig by -1 time lag\n",
    "\n",
    "\n",
    "## Plot original ts vs shifted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:37.774704Z",
     "start_time": "2021-05-29T22:32:37.685737Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shift the orig ts from -1 to -52 lags\n",
    "\n",
    "\n",
    "\n",
    "## Concatenate ts_orig and shifted_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:37.956326Z",
     "start_time": "2021-05-29T22:32:37.776753Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot the correlations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:38.227281Z",
     "start_time": "2021-05-29T22:32:37.958845Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shift the ts_orig by -1 time lag\n",
    "\n",
    "\n",
    "## Plot original ts vs shifted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:38.310889Z",
     "start_time": "2021-05-29T22:32:38.229220Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shift the orig ts from -1 to -52 lags\n",
    "\n",
    "\n",
    "\n",
    "## Concatenate ts_orig and shifted_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:38.487906Z",
     "start_time": "2021-05-29T22:32:38.312557Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot the correlations \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF & PACF  Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation Function Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - \"The **autocorrelation function** is a function that represents autocorrelation of a time series as a function of the time lag.\"\n",
    "- The autocorrelation function tells interesting stories about trends and seasonality. For example, if the original time series repeats itself every five days, you would expect to see a spike in the autocorrelation function at 5 days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:38.717342Z",
     "start_time": "2021-05-29T22:32:38.490450Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use panda's autocorrelation plot on the ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use statsmodels ACF plot on ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:38.949452Z",
     "start_time": "2021-05-29T22:32:38.719572Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use plot_acf on ts_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial-Autocorrelation Function Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> \"The **partial autocorrelation function** can be interpreted as a regression of the series against its past lags.\n",
    " \n",
    " > It helps you come up with a possible order for the auto regressive term. The terms can be interpreted the same way as a standard linear regression, that is the contribution of a change in that particular lag while holding others constant. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:39.191742Z",
     "start_time": "2021-05-29T22:32:38.953453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Use plot_pacf on ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use plot_pacf on ts_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def  `plot_acf_pacf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:15:23.613173Z",
     "start_time": "2021-05-29T23:15:23.610464Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts,figsize=(9,6),suptitle=None,sup_y = 1.01):\n",
    "    \"\"\"Plot pacf and acf using statsmodels\"\"\"\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:39.680927Z",
     "start_time": "2021-05-29T22:32:39.258726Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Use function on differenced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:40.112701Z",
     "start_time": "2021-05-29T22:32:39.683537Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Use function on original data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When time series show autocorrelation, it is an indicator to use more complex time series models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Time Series Modeling with `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR/MA MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Model (AR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "An autoregressive (AR) model is when a value from a time series is regressed on previous values from the same time series.\n",
    "\n",
    "In words, the mathematical idea is the following:\n",
    "\n",
    "$$ \\text{Today = constant + slope} \\times \\text{yesterday + noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "$$\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$$\n",
    "\n",
    "Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follows an oscillatory process\n",
    "\n",
    "\n",
    "<!---\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-arma-models-online-ds-pt-100719/master/images/AR_model.png\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-arma-models-online-ds-pt-100719/master/images/AR_PACF.png\"> --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:40.936473Z",
     "start_time": "2021-05-29T22:32:40.115867Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fit an AR model (using ARIMA with order (1,0,0))\n",
    "\n",
    "## Display mode. summary and plot diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:10:24.822761Z",
     "start_time": "2021-05-29T23:10:24.820844Z"
    }
   },
   "outputs": [],
   "source": [
    "## funtionize diagnosing\n",
    "def diagnose_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:10:28.290491Z",
     "start_time": "2021-05-29T23:10:28.288169Z"
    }
   },
   "outputs": [],
   "source": [
    "## Repeat model and diagnose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The  Moving Average Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Moving Average model can be described as the weighted sum of today's and yesterday's noise.\n",
    "\n",
    "In words, the mathematical idea is the following:\n",
    "\n",
    "$$ \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "$$\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$$\n",
    "\n",
    "Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follow an oscillatory process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:10:33.232483Z",
     "start_time": "2021-05-29T23:10:33.230332Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fit a MA 1 ARIMA(0,0,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is performing better? (Use AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:10:39.208581Z",
     "start_time": "2021-05-29T23:10:39.206428Z"
    }
   },
   "outputs": [],
   "source": [
    "## can compare via the aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-order AR and MA models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are not limited to using just one time-step in our models. \n",
    "- The number of time steps used is called the **order** of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Order AR/MA Models:\n",
    "\n",
    "- AR: $$Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$$\n",
    "- MA: $$Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$$\n",
    "\n",
    "#### Second-Order AR/MA Models\n",
    "\n",
    "- AR(2): $$Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t$$\n",
    "- MA(2): $$Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of AR (Auto-Regressive) terms (`p`): \n",
    "\n",
    "- `p` is the auto-regressive part of the model. It indicates how many AR coefficients should be included based on `p` # of timesteps/lags.\n",
    "    -  For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
    "\n",
    "#### Number of MA (Moving Average) terms (q): \n",
    "\n",
    "- `q` is the moving average part of the model which is used to set the error of the model as a linear combination of the error values observed at previous time points in the past.\n",
    "    -  For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where `e(i)` is the difference between the moving average at ith instant and actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New  AR/MA model (depending on AIC of previous models) using a higher order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:43.239356Z",
     "start_time": "2021-05-29T22:32:42.574990Z"
    }
   },
   "outputs": [],
   "source": [
    "## Repeat model and diagnose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Did the model improve? What if we weren't limited to just AR or just MA?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA & ARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can combine BOTH an AR and MA model into one using an using an **AutoregRessive Moving Average** model (ARMA model).\n",
    "    - We need to determine best number of p's and q's to use. \n",
    "- In actuality, we will go straight to using a slightly more advanced version of ARMA, which will actually difference our time series for us, allowing us to use the raw original ts for training. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ARIMA Time Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common methods used in time series forecasting is known as the ARIMA model, which stands for **AutoregRessive Integrated Moving Average**. ARIMA is a model that can be fitted to time series data in order to better understand or predict future points in the series.\n",
    "\n",
    "\n",
    ">- **An ARIMA is specified with (`p`,`d`,`q`)**\n",
    "    - Number of AR (Auto-Regressive) terms (p)\n",
    "    - Number of Differences (`d`):\n",
    "        - `d` is the **Integrated** component of an ARIMA model. The number of lag values to subtract from the current observation (aka differencing). \n",
    "    - Number of MA (Moving Average) terms ($q$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T23:10:55.960134Z",
     "start_time": "2021-05-29T23:10:55.958329Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make an ARMA model with p=1, q=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the model and order to use via PACF/ACF _(if you can)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I've heard many different rules of thumb on how to use the PACF/ACF plots from earlier to determine whether to use AR/MA and how many p/q's to use. \n",
    "    - In my experience, it is rarely easy to see an obvious answer from these plots and it is better to use a gridsearch to determine the best performing model.\n",
    "    - I have also heard competing answers on whether you should use the PACF/ACF for the original time series of the differenced time series.\n",
    "    \n",
    "- That all being said..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:44.379082Z",
     "start_time": "2021-05-29T22:32:43.900648Z"
    }
   },
   "outputs": [],
   "source": [
    "## PLotting the original vs differenced timeseires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:44.791408Z",
     "start_time": "2021-05-29T22:32:44.381484Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot raw time series PACF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:45.196663Z",
     "start_time": "2021-05-29T22:32:44.793410Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plotn differenced time sereis pacf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:45.249734Z",
     "start_time": "2021-05-29T22:32:45.199212Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save both figures in a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining AR(p) and MA(q) using PACF [FROM  CANVAS]\n",
    "\n",
    "- AR(p):\n",
    "    - ACF for AR(p) would be strong until lag of p, then stagnant, then trail off. \n",
    "    - PACF for AR(p): Generally no correlation for lag values beyond p.\n",
    "- MA(q):\n",
    "    - ACF for MA(q) would show strong correlation up to a lag of q, the immedately delcine to minimal/no correction.\n",
    "    - PACF would show strong relationship to the lag and tailing off to no correlation afterwards.\n",
    "   \n",
    "- Notation is generally ARMA(p,q)\n",
    "- Example: ARMA(2,1) model equation\n",
    "     $$Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t$$\n",
    "\n",
    "| Param| AR(p)   |   MA(q)  | ARMA(p,q)|\n",
    "|------|------|------|------|\n",
    "|   ACF | Tails off   |  Cuts off after lag q |  Tails off   |\n",
    "|   PACF | Cuts off after lag p  |   Tails off  |  Tails off  |\n",
    "  parameters and use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:45.477937Z",
     "start_time": "2021-05-29T22:32:45.252292Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualize either figure to look for the above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Determining AR(p) and MA(q) using PACF [INFO FROM UDEMY]\n",
    "\n",
    "- **USE ACF TO JUDGE IF MA OR AR COMPONENTS:**\n",
    "    - If lag 1 is positive: AR\n",
    "    - If lag 1 is negatige: MA\n",
    "    \n",
    "- **PACF is best for picking AR (p)**\n",
    "- **ACF is best for picking MA(q)**\n",
    "    - If sharp drop off at lag of k (k= point on x axis) means use an AR model of order k.\n",
    "    - If slow gradual decline: use MA\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:45.810691Z",
     "start_time": "2021-05-29T22:32:45.479875Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining AR(p) and MA(q) using PACF [Centra Lecturer]\n",
    "\n",
    "<img src=\"ds-time_series-main/img/armaguidelines.png\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:46.284558Z",
     "start_time": "2021-05-29T22:32:45.812857Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining `p`,`d`,`q` programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:46.350184Z",
     "start_time": "2021-05-29T22:32:46.286843Z"
    }
   },
   "outputs": [],
   "source": [
    "### From SARIMA Models Lab\n",
    "import itertools\n",
    "from tqdm.notebook import trange\n",
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:56.845896Z",
     "start_time": "2021-05-29T22:32:46.352178Z"
    }
   },
   "outputs": [],
   "source": [
    "## Loop through pdq_list, make an ARIMA model\n",
    "# save p,d,q and aic to a model_aic list\n",
    "model_aics=None\n",
    "\n",
    "## Make Results into a df and sort by aic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:56.939581Z",
     "start_time": "2021-05-29T22:32:56.849415Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save best_params as a dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:57.955021Z",
     "start_time": "2021-05-29T22:32:57.017376Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a best_model using the best_params from our loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasts vs Predictions (`statsmodels`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.forecast()`/`model.get_forecast()` are designed for predictions **after the training data**. It needs the # of time steps in the future to forecast. \n",
    "- `model.forecast()` will return JUST the mean value for the forecast.\n",
    "\n",
    "\n",
    "- `forecast = model.get_forecast()` will return a special `PredictionResultsWrapper` object that contains:\n",
    "    - `forecast.conf_int()`: the lower and upper limits of the confidence indterval (as a dataframe).\n",
    "        ` forecast.predicted_mean`: the mean value of the forecast (returned as a series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.027372Z",
     "start_time": "2021-05-29T22:32:57.957325Z"
    }
   },
   "outputs": [],
   "source": [
    "## forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.098191Z",
     "start_time": "2021-05-29T22:32:58.029590Z"
    }
   },
   "outputs": [],
   "source": [
    "## get_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.161567Z",
     "start_time": "2021-05-29T22:32:58.100876Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check out the pred's predicted_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.228114Z",
     "start_time": "2021-05-29T22:32:58.164529Z"
    }
   },
   "outputs": [],
   "source": [
    "## check out pred's conf_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.302529Z",
     "start_time": "2021-05-29T22:32:58.230700Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get confidence intervals and predicted mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.655095Z",
     "start_time": "2021-05-29T22:32:58.304781Z"
    }
   },
   "outputs": [],
   "source": [
    "### PLot forecast with confidence intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:58.718315Z",
     "start_time": "2021-05-29T22:32:58.657593Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_pred():\n",
    "    \"\"\"Takes a PredictionResultsWrapper from statsmodels\n",
    "    extracts the confidence intervals and predicted mean and returns in a df\"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_forecast_from_df():\n",
    "    \"\"\"Takes a forecast_df from get_df_from_pred and optionally \n",
    "    the training/original time series.\n",
    "    \n",
    "    Plots the original ts, the predicted mean and the \n",
    "    confidence invtervals (using fill between)\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:32:59.940927Z",
     "start_time": "2021-05-29T22:32:58.720936Z"
    }
   },
   "outputs": [],
   "source": [
    "## Combine getting a new model, forecast_df, and plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.predict/get_prediction` return a prediction for times within the original training period. (can also get into future)\n",
    "    - Instead of the number of timesteps, predict needs the start and end dates for the forecast. `start=None, end=None,`\n",
    "        - Note: if no times are provided, it will produce predictions for the entire training time series.\n",
    "\n",
    "    \n",
    "- Dynamic vs One-Step-Ahead Predictions:\n",
    "    - Additionally, since predictions are during the same times as the actual data, we have the option to get dynamic/non-dynamic forecasts.\n",
    "    - `dynamic=True`: will behave like a forecast where each step in time is predicted based on the previously predicted time. \n",
    "    - `dynamic=False`: will ONLY predict one step ahead in time, so the predictions for all data points were ONLY guessing 1 step ahead for each point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:00.003363Z",
     "start_time": "2021-05-29T22:32:59.943162Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get one-step-ahead preditions for the last 12 weeks of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:00.077042Z",
     "start_time": "2021-05-29T22:33:00.017909Z"
    }
   },
   "outputs": [],
   "source": [
    "## get_prediction from model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:00.140885Z",
     "start_time": "2021-05-29T22:33:00.080894Z"
    }
   },
   "outputs": [],
   "source": [
    "## conf_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:00.202452Z",
     "start_time": "2021-05-29T22:33:00.143120Z"
    }
   },
   "outputs": [],
   "source": [
    "## Also contains the .predicted mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:00.684089Z",
     "start_time": "2021-05-29T22:33:00.204598Z"
    }
   },
   "outputs": [],
   "source": [
    "## plot one step ahead forecasat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:01.140651Z",
     "start_time": "2021-05-29T22:33:00.686233Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Using the above functions, get a dyanmic prediction and plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Q: What do we notice about the dynamic vs non-dynamic predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA & SARIMAX MODELS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seasonal ARIMA Models add a longer/larger seasonal ARIMA model combined with a non-seasonal ARIMA model.\n",
    "\n",
    "* `(p, d, q)` are the non-seasonal parameters described above.\n",
    "* `(P, D, Q)` follow the same definition but are applied to the seasonal component of the time series. \n",
    "* The term `s` a.k.a. `m` is the periodicity of the time series (4 for quarterly periods, 12 for yearly periods, etc.).\n",
    "\n",
    "A detailed article on these parameters is available [HERE](https://www.quantstart.com/articles/Autoregressive-Integrated-Moving-Average-ARIMA-p-d-q-Models-for-Time-Series-Analysis).\n",
    "\n",
    "- Note: we will use the `SARIMAX` model from statsmodels, which allows for another variable (`X` aka exog) to be used in the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:01.199297Z",
     "start_time": "2021-05-29T22:33:01.142978Z"
    }
   },
   "outputs": [],
   "source": [
    "## make sure have pdfq=best params\n",
    "pdq = None\n",
    "pdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:02.188541Z",
     "start_time": "2021-05-29T22:33:01.201497Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a SARIMAX model using best pdq from ARIMA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Q: Does the seasonal ARIMA with seasonal order= (0,0,0,0)look familiar?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:03.122035Z",
     "start_time": "2021-05-29T22:33:02.191234Z"
    }
   },
   "outputs": [],
   "source": [
    "## Copy the above code and replace the SARIMAX with .arima.ARIMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Seasonal Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Figuring out the seasonal component can be tricky. \n",
    "- For one, we have to know the value for $m$, which is how many time steps should be considered a season. \n",
    "    - Use seasonal decompose to look for potential seasonality/$m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:04.197946Z",
     "start_time": "2021-05-29T22:33:03.124666Z"
    }
   },
   "outputs": [],
   "source": [
    "## use seasonal decompose and plot to look for m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:04.481855Z",
     "start_time": "2021-05-29T22:33:04.200532Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot JUST the seasonal component and add a grid \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the value for $m$ inferred above, try making a SARIMAX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:09.154453Z",
     "start_time": "2021-05-29T22:33:04.485021Z"
    }
   },
   "outputs": [],
   "source": [
    "## using all of our functions to train our model, get and plot forecast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionize Entire  process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:45:43.546537Z",
     "start_time": "2021-05-29T22:45:43.491969Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:12.467608Z",
     "start_time": "2021-05-29T22:48:10.488778Z"
    }
   },
   "outputs": [],
   "source": [
    "## Test functionizing process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pmdarima.auto_arima`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While we could construct another loop/grid and add a seasonal PDQ list to iterate through (see the SARIMAX Lab for example).\n",
    "- There is a package called `pmdarima` which makes an auto-arima model for python (like there is for R)\n",
    "    - http://alkaline-ml.com/pmdarima/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:09.959590Z",
     "start_time": "2021-05-29T22:33:09.472652Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U pmdarima\n",
    "import pmdarima as pmd\n",
    "# help(pmd.auto_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:33:33.899338Z",
     "start_time": "2021-05-29T22:33:33.622740Z"
    }
   },
   "outputs": [],
   "source": [
    "## Cut down ts to 2019-present (for time sake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:34:59.655039Z",
     "start_time": "2021-05-29T22:34:53.099764Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use auto_arima \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:35:48.444931Z",
     "start_time": "2021-05-29T22:35:47.768606Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Make a sarimax using params from auto_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Modeling with Crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the examples we've made in this notebook:\n",
    "    - Select a crime from our original df.\n",
    "    - Create a train/test/ split.\n",
    "    - Train/tune a model using the training data. \n",
    "    - Get the model's forecast for the test data's period. \n",
    "    - Plot the model's forecast vs actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:28.730307Z",
     "start_time": "2021-05-29T22:48:28.454526Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:31.060197Z",
     "start_time": "2021-05-29T22:48:30.836596Z"
    }
   },
   "outputs": [],
   "source": [
    "## save chosen ts as var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:32.337884Z",
     "start_time": "2021-05-29T22:48:32.283981Z"
    }
   },
   "outputs": [],
   "source": [
    "# do a train-test-split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:33.165399Z",
     "start_time": "2021-05-29T22:48:32.865862Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Do Train test split and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:37.102859Z",
     "start_time": "2021-05-29T22:48:36.723999Z"
    }
   },
   "outputs": [],
   "source": [
    "### Check PACF/ACF to infer p/q (if possible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:40.317140Z",
     "start_time": "2021-05-29T22:48:39.960626Z"
    }
   },
   "outputs": [],
   "source": [
    "### Check PACF/ACF to infer p/q (if possible)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possible values:\n",
    "    - p:\n",
    "    - d:\n",
    "    - q:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:46.525461Z",
     "start_time": "2021-05-29T22:48:45.879191Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use Seasonal Decompose to check for seasonality \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:48:54.268598Z",
     "start_time": "2021-05-29T22:48:53.910861Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:49:27.136455Z",
     "start_time": "2021-05-29T22:49:27.082075Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get forecast steps from test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:50:32.477290Z",
     "start_time": "2021-05-29T22:50:32.153832Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:53:33.358123Z",
     "start_time": "2021-05-29T22:53:19.948802Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fit a model and evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:54:29.795085Z",
     "start_time": "2021-05-29T22:54:28.991558Z"
    }
   },
   "outputs": [],
   "source": [
    "## If happy with the model's test perforamance, retrain on entire ts and forecast into future\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:40:20.525348Z",
     "start_time": "2021-05-29T18:36:39.671Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "class BlockTimeSeriesSplit(_BaseKFold): #sklearn.model_selection.TimeSeriesSplit):\n",
    "    \"\"\"A variant of sklearn.model_selection.TimeSeriesSplit that keeps train_size and test_size\n",
    "    constant across folds. \n",
    "    Requires n_splits,train_size,test_size. train_size/test_size can be integer indices or float ratios \"\"\"\n",
    "    def __init__(self, n_splits=5,train_size=None, test_size=None, step_size=None, method='sliding'):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.step_size = step_size\n",
    "        if 'sliding' in method or 'normal' in method:\n",
    "            self.method = method\n",
    "        else:\n",
    "            raise  Exception(\"Method may only be 'normal' or 'sliding'\")\n",
    "        \n",
    "    def split(self,X,y=None, groups=None):\n",
    "        import math \n",
    "        method = self.method\n",
    "        ## Get n_samples, trian_size, test_size, step_size\n",
    "        n_samples = len(X)\n",
    "        test_size = self.test_size\n",
    "        train_size =self.train_size\n",
    "      \n",
    "                \n",
    "        ## If train size and test sze are ratios, calculate number of indices\n",
    "        if train_size<1.0:\n",
    "            train_size = math.floor(n_samples*train_size)\n",
    "        \n",
    "        if test_size <1.0:\n",
    "            test_size = math.floor(n_samples*test_size)\n",
    "            \n",
    "        ## Save the sizes (all in integer form)\n",
    "        self._train_size = train_size\n",
    "        self._test_size = test_size\n",
    "        \n",
    "        ## calcualte and save k_fold_size        \n",
    "        k_fold_size = self._test_size + self._train_size\n",
    "        self._k_fold_size = k_fold_size    \n",
    "        \n",
    "\n",
    "    \n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        ## Verify there is enough data to have non-overlapping k_folds\n",
    "        if method=='normal':\n",
    "            import warnings\n",
    "            if n_samples // self._k_fold_size <self.n_splits:\n",
    "                warnings.warn('The train and test sizes are too big for n_splits using method=\"normal\"\\n\\\n",
    "                switching to method=\"sliding\"')\n",
    "                method='sliding'\n",
    "                self.method='sliding'\n",
    "                              \n",
    "                  \n",
    "            \n",
    "        if method=='normal':\n",
    "\n",
    "            margin = 0\n",
    "            for i in range(self.n_splits):\n",
    "\n",
    "                start = i * k_fold_size\n",
    "                stop = start+k_fold_size\n",
    "\n",
    "                ## change mid to match my own needs\n",
    "                mid = int(start+self._train_size)\n",
    "                yield indices[start: mid], indices[mid + margin: stop]\n",
    "        \n",
    "\n",
    "        elif method=='sliding':\n",
    "            \n",
    "            step_size = self.step_size\n",
    "            if step_size is None: ## if no step_size, calculate one\n",
    "                ## DETERMINE STEP_SIZE\n",
    "                last_possible_start = n_samples-self._k_fold_size #index[-1]-k_fold_size)\\\n",
    "                step_range =  range(last_possible_start)\n",
    "                step_size = len(step_range)//self.n_splits\n",
    "            self._step_size = step_size\n",
    "                \n",
    "            \n",
    "            for i in range(self.n_splits):\n",
    "                if i==0:\n",
    "                    start = 0\n",
    "                else:\n",
    "                    start = prior_start+self._step_size #(i * step_size)\n",
    "\n",
    "                stop =  start+k_fold_size            \n",
    "                ## change mid to match my own needs\n",
    "                mid = int(start+self._train_size)\n",
    "                prior_start = start\n",
    "                yield indices[start: mid], indices[mid: stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:40:20.526360Z",
     "start_time": "2021-05-29T18:36:39.673Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (TimeSeriesSplit,train_test_split,\n",
    "                                     GridSearchCV,cross_val_score,KFold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `BlockTimeSeriesSplit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:40:20.527350Z",
     "start_time": "2021-05-29T18:36:39.677Z"
    }
   },
   "outputs": [],
   "source": [
    "## BlockTimeSeriesSplit \n",
    "split_ts = BlockTimeSeriesSplit(n_splits = 5, \n",
    "                                train_size=0.3,\n",
    "                                test_size=0.1,\n",
    "                                method='sliding')#train_size=840, test_size=10*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:40:20.528477Z",
     "start_time": "2021-05-29T18:36:39.680Z"
    }
   },
   "outputs": [],
   "source": [
    "master_date_index = ts.index.to_series()\n",
    "n=0\n",
    "\n",
    "for train_index,test_index in split_ts.split(ts):\n",
    "    train_ts = master_date_index.iloc[train_index]\n",
    "    test_date_index = master_date_index.iloc[test_index]\n",
    "    train = ts\n",
    "#\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:40:20.529573Z",
     "start_time": "2021-05-29T18:36:39.683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# master_date_index=df_to_model.index.to_series()\n",
    "\n",
    "# n=0\n",
    "# dashes = '---'*20\n",
    "# for train_index, test_index in split_ts.split(df_to_model):  \n",
    "    \n",
    "#     print(f'\\n{dashes}\\nsplit {n}')\n",
    "#     train_date_index = master_date_index.iloc[train_index]\n",
    "#     test_date_index = master_date_index.iloc[test_index]\n",
    "#     ji.index_report(train_date_index)\n",
    "#     ji.index_report(test_date_index)\n",
    "#     n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
