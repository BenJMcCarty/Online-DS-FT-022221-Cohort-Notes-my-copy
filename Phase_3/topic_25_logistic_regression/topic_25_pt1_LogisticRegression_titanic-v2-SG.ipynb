{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 25-Pt 1: Intro to Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- onl01-dtsc-ft-022221\n",
    "- 05/06/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blog Post Deadline Extended until Monday at 10 AM EST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Today:\n",
    "    - Types of machine learning.\n",
    "        - Supervised vs Unsupervised Learning\n",
    "        - Regression vs Classification \n",
    "    - From Linear to Logistic Regression - Theory\n",
    "    - Applying Logistic Regression with `scikit-learn`\n",
    "        - Proper preprocessing with train-test-split.\n",
    "    - Evaluating Classifiers\n",
    "        - Confusion Matrices\n",
    "        - Accuracy, ~~Precision, Recall, F1-Score~~\n",
    "\n",
    "\n",
    "\n",
    "- For Next Class:\n",
    "    - Classification Metrics \n",
    "        - Confusion Matrices\n",
    "        - Accuracy, Precision, Recall, F1-Score\n",
    "        - ROC-AUC curve\n",
    "    - Class Imbalance Problems\n",
    "    - Functionizing evaluating classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/ai_machine_learning_deep_learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"The term **_Supervised Learning_** refers to a class of machine learning algorithms that can \"learn\" a task through **_labeled training data_**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-intro-to-supervised-learning-v2-1-online-ds-pt-100719/master/images/new_ml-hierarchy.png\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All machine learning models fall into one of two categories:\n",
    "    - Regressors/Regression\n",
    "    - Classifiers/Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to find the **relationship** and predict a specific value.\n",
    "\n",
    "- Examples of regressions:\n",
    "    - House prices\n",
    "    - Salary\n",
    "    - Reviews/Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to identify what features can predict which class a particular observation/row belongs to.\n",
    "- Can be a \"binary classification\" \n",
    "    - \"yes\" or \"no\"\n",
    "    - Survived or died.\n",
    "    - Diabetic or not-diabetic\n",
    "- Can also be a \"multiclass classification\"\n",
    "    - Which type of flower?\n",
    "    - Will a football game end one team winning, or the other team, or a tie?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Linear Regression to Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/online-dtsc-pt-041320-cohort-notes/master/assets/images/logistic_vs_linear.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\hat y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n = \\sum_{i=0}^{N} \\beta_i x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output is specifying the **predicted value** for the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Use Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output is specifying the **probability** of belonging to a particular group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visual Example:\n",
    "    - https://www.desmos.com/calculator/y2ilpxiqys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform from linear regression!\n",
    "\n",
    "$$ \\large \\hat y = \\sum_{i=0}^{N} \\beta_i x_i $$\n",
    "\n",
    "$$\\large P = \\displaystyle \\frac{1}{1+e^{-\\hat y}} = \\frac{1}{1+e^{-\\sum_{i=0}^{N} \\beta_i x_i}} $$\n",
    "\n",
    "$$ \\large = \\frac{1}{1+e^{-\\beta_0}e^{-\\beta_1 x_1}\\ldots e^{-\\beta_N x_N}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Passenger Survival on the Titanic with `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:57.462231Z",
     "start_time": "2021-05-06T15:53:54.807392Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "# import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:57.780008Z",
     "start_time": "2021-05-06T15:53:57.464973Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jirvingphd/dsc-dealing-missing-data-lab-online-ds-ft-100719/master/titanic.csv\"\n",
    "df = pd.read_csv(url,index_col=0,na_values='?')\n",
    "relevant_columns = ['Pclass', 'Age', 'SibSp', 'Fare', 'Sex', 'Embarked', 'Survived']\n",
    "df = df[relevant_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:57.790624Z",
     "start_time": "2021-05-06T15:53:57.782487Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Survived'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:58.065480Z",
     "start_time": "2021-05-06T15:53:57.792833Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(ncols=2,figsize=(10,4))\n",
    "sns.scatterplot(data=df, x='Fare',y='Survived',ax=ax[0])\n",
    "sns.scatterplot(data=df, x='Age',y='Survived',ax=ax[1])\n",
    "fig.suptitle('X Features vs Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:58.568611Z",
     "start_time": "2021-05-06T15:53:58.067113Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(ncols=2,figsize=(10,4))\n",
    "sns.regplot(data=df, x='Fare',y='Survived',ax=ax[0])\n",
    "sns.regplot(data=df, x='Age',y='Survived',ax=ax[1])\n",
    "fig.suptitle('X Features vs Survived - Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T22:26:15.520827Z",
     "start_time": "2020-03-24T22:26:15.518673Z"
    }
   },
   "source": [
    "### Q: What are the preprocessing steps I need to perform before I create the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recast data types\n",
    "- Train-test-split\n",
    "- Fill/drop in missing/null values\n",
    "- Feature Selection / Feature Engineering (interaction terms)\n",
    "- Handling categorial variables\n",
    "    - One Hot Encoding \n",
    "    - Label Encoding\n",
    "- Handling Outliers (maybe)\n",
    "- Normalizing/Standardizing our data\n",
    "\n",
    "- **Multicollinearity (does it still matter as much for Logistic?)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:58.575988Z",
     "start_time": "2021-05-06T15:53:58.570041Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check out the .info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:58.583067Z",
     "start_time": "2021-05-06T15:53:58.577355Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check Object cols value_counts\n",
    "display(df['Embarked'].value_counts(dropna=False),\n",
    "        df['Sex'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:53:58.790275Z",
     "start_time": "2021-05-06T15:53:58.785293Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separate X and y and train-test-split\n",
    "target = 'Survived'\n",
    "\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# Perform test train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:54:03.427112Z",
     "start_time": "2021-05-06T15:54:03.424956Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check for nulls in training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:48.928740Z",
     "start_time": "2021-05-06T15:22:48.926491Z"
    }
   },
   "outputs": [],
   "source": [
    "## Specify which values to impute with which method\n",
    "\n",
    "## Most frequent\n",
    "\n",
    "## Fill with median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:54:14.627239Z",
     "start_time": "2021-05-06T15:54:14.625244Z"
    }
   },
   "outputs": [],
   "source": [
    "## Copying X_train and X_test as start of X_train_tf,X_test_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:48.951010Z",
     "start_time": "2021-05-06T15:22:48.934936Z"
    }
   },
   "outputs": [],
   "source": [
    "## Impute the columns with most-frequent value\n",
    "\n",
    "\n",
    "## Verify it worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:48.970891Z",
     "start_time": "2021-05-06T15:22:48.953057Z"
    }
   },
   "outputs": [],
   "source": [
    "## Impute cols with 0s\n",
    "\n",
    "## Verify it worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:54:47.975705Z",
     "start_time": "2021-05-06T15:54:47.973678Z"
    }
   },
   "outputs": [],
   "source": [
    "## Specifing which cols to encode and which to scale.\n",
    "#  make cat_cols and num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:54:53.270371Z",
     "start_time": "2021-05-06T15:54:53.268294Z"
    }
   },
   "outputs": [],
   "source": [
    "## Encode cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:54:59.416841Z",
     "start_time": "2021-05-06T15:54:59.414729Z"
    }
   },
   "outputs": [],
   "source": [
    "## Scaling Num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:55:02.349338Z",
     "start_time": "2021-05-06T15:55:02.347089Z"
    }
   },
   "outputs": [],
   "source": [
    "## Combine Num and Cat Cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:55:14.665586Z",
     "start_time": "2021-05-06T15:55:14.663597Z"
    }
   },
   "outputs": [],
   "source": [
    "## check the .decribe of X_train_tf for scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Logistic Regression with `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:55:37.465162Z",
     "start_time": "2021-05-06T15:55:37.463288Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fit a logistic regression model with defaults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### But how do we know how GOOD it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.094305Z",
     "start_time": "2021-05-06T15:22:49.087927Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the .score of the model\n",
    "log_reg.score(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.105125Z",
     "start_time": "2021-05-06T15:22:49.096298Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get the model's .score for training and test set \n",
    "print(f\"Training Score:\\t{log_reg.score(X_train_tf,y_train):.2f}\")\n",
    "print(f\"Test Score:\\t{log_reg.score(X_test_tf,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But what \"score\" is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.113167Z",
     "start_time": "2021-05-06T15:22:49.107301Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get Predictions for training and test data to check metrics functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.125823Z",
     "start_time": "2021-05-06T15:22:49.121205Z"
    }
   },
   "outputs": [],
   "source": [
    "## is it r-squared?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hmmm...its not $R^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.134942Z",
     "start_time": "2021-05-06T15:22:49.130504Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try root_mean_square_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T14:53:52.812312Z",
     "start_time": "2021-05-06T14:53:52.809098Z"
    }
   },
   "source": [
    "> Hmmm...its not $\\text{RMSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.141779Z",
     "start_time": "2021-05-06T15:22:49.137612Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ah-ha! The default `.score` for a classification model is **accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.147084Z",
     "start_time": "2021-05-06T15:22:49.143660Z"
    }
   },
   "outputs": [],
   "source": [
    "### Getting our model's coefficients\n",
    "## Our function from last class\n",
    "def get_coefficients(model,X_train):\n",
    "    coeffs = pd.Series(model.coef_.flatten(), index=X_train.columns)\n",
    "    coeffs['intercept'] = model.intercept_[0]\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:56:30.334821Z",
     "start_time": "2021-05-06T15:56:30.332954Z"
    }
   },
   "outputs": [],
   "source": [
    "## get the model's coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Our Model's Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For classification tasks, it can be extremely helpful to examine a \"Confusion Matrix\" to understand how our model is wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:56:40.834083Z",
     "start_time": "2021-05-06T15:56:40.832060Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use metrics.confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:56:44.255886Z",
     "start_time": "2021-05-06T15:56:44.253849Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use metrics.plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- The Confusion Matrix separated out the correct (true) predictions for the positive class (1) and negative class (0). \n",
    "\n",
    "- **_True Positives (TP)_**: The number of observations where the model predicted the person has the disease (1), and they actually do have the disease (1).\n",
    "\n",
    "- **_True Negatives (TN)_**: The number of observations where the model predicted the person is healthy (0), and they are actually healthy (0).\n",
    "\n",
    "- **_False Positives (FP)_**: The number of observations where the model predicted the person has the disease (1), but they are actually healthy (0). \n",
    "\n",
    "- **_False Negatives (FN)_**: The number of observations where the model predicted the person is healthy (0), but they actually have the disease (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:56:56.705707Z",
     "start_time": "2021-05-06T15:56:56.703616Z"
    }
   },
   "outputs": [],
   "source": [
    "## Remake the conf matrix (raw counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[TN,FP],\n",
    "[FN,TP]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.352628Z",
     "start_time": "2021-05-06T15:22:49.350190Z"
    }
   },
   "outputs": [],
   "source": [
    "## SLice out TN/FP/etc from cm\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None\n",
    "TP = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.356853Z",
     "start_time": "2021-05-06T15:22:49.354332Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Make sure we got the order right\n",
    "print(TN,FP)\n",
    "print(FN,TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics are based on the confusion matrices of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\text{Accuracy} = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}} $$\n",
    "\n",
    "> \"Out of all the predictions our model made, what percentage were correct?\"\n",
    "- \"Accuracy is the most common metric for classification. It provides a solid holistic view of the overall performance of our \n",
    "model.\"\n",
    "\n",
    "#### When to use?\n",
    "- **Accuracy** is good for non-technical audiences (but can be misleading with imbalanced classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:57:18.018917Z",
     "start_time": "2021-05-06T15:57:18.016176Z"
    }
   },
   "outputs": [],
   "source": [
    "## calcualte accuracy manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:57:20.033123Z",
     "start_time": "2021-05-06T15:57:20.031221Z"
    }
   },
   "outputs": [],
   "source": [
    "## compare against the accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: Normalized Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:57:29.009150Z",
     "start_time": "2021-05-06T15:57:29.007088Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try using normalize=true for confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:57:30.890954Z",
     "start_time": "2021-05-06T15:57:30.889059Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Try using normalize=true for plot confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I know if my accuracy score is good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Does your model predict better than chance/just getting the class distribution?\n",
    "- Compare your accuracy to your normalized value counts for y\n",
    "- Compare your model against a `DummyClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.554629Z",
     "start_time": "2021-05-06T15:22:49.548928Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the class balance for the y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.562354Z",
     "start_time": "2021-05-06T15:22:49.556771Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the class balance for y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.572236Z",
     "start_time": "2021-05-06T15:22:49.564568Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "## Make and fit  dummy classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.580170Z",
     "start_time": "2021-05-06T15:22:49.574252Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get the model's .score\n",
    "print(f\"Training Score:\\t{model.score(X_train_tf,y_train):.2f}\")\n",
    "print(f\"Test Score:\\t{model.score(X_test_tf,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:58:16.635393Z",
     "start_time": "2021-05-06T15:58:16.633204Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But accuracy isn't the best metric when you have imbalanced classes. \n",
    "- Next class we will introduce more classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Part 2: Classification Metrics / Evaluating Classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [The 5 Classification Evaluation metrics every Data Scientist must know](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\text{Accuracy} = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}} $$\n",
    "\n",
    "> \"Out of all the predictions our model made, what percentage were correct?\"\n",
    "- \"Accuracy is the most common metric for classification. It provides a solid holistic view of the overall performance of our \n",
    "model.\"\n",
    "\n",
    "#### When to use?\n",
    "- **Accuracy** is good for non-technical audiences (but can be misleading with imbalanced classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.811393Z",
     "start_time": "2021-05-06T15:22:49.806412Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"**_Precision_** measures what proportion of predicted Positives is truly Positive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\text{Precision} = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use?\n",
    "- **Use precision** when the cost of acting is high and acting on a positive is costly.\n",
    "   - e.g. Allocating resources/interventions for prisoners who are at-risk for recidivism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.819526Z",
     "start_time": "2021-05-06T15:22:49.813411Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_Recall_** indicates what percentage of the classes we're interested in were actually captured by the model.\"\n",
    "$$ \\large \\text{Recall} = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use?\n",
    "- **Use recall** when the number of true positives/opportunities is small and you don’t want to miss one.\n",
    "    - e.g. cancer diagnosis. (telling someone they do not have cancer when they actually do is fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.829210Z",
     "start_time": "2021-05-06T15:22:49.821709Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/precisionrecall.png' width=10%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F_1$ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score represents the **_Harmonic Mean of Precision and Recall_**.  In short, this means that the F1 score cannot be high without both precision and recall also being high. When a model's F1 score is high, you know that your model is doing well all around. \n",
    "\n",
    "> Harmonic Mean: \"the reciprocal of the arithmetic mean of the reciprocals of a given set of observatins.\" - *[Wikipedia](https://en.wikipedia.org/wiki/Harmonic_mean)*\n",
    "\n",
    "#### Arithmetic Mean:\n",
    "\n",
    "$$\\large \\bar{X} = \\frac{a+b+c}{n} $$\n",
    "\n",
    "#### Harmonic Mean:\n",
    "\n",
    "$$ \\large \\bar{X} = \\frac{n}{\\frac{1}{a}+ \\frac{1}{b}+ \\frac{1}{c}}$$\n",
    "\n",
    "\n",
    "**The formula for F1 score is:**\n",
    "\n",
    "> $$ \\text{F1 score} =  \\frac{2}{\\text{Precision}^{-1}\\ x\\ \\text{Recall}^{-1}}= 2\\ \\frac{\\text{Precision}\\ x\\ \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use?\n",
    "- **F1 score** is really the most informative about overall model quality.\n",
    "- BUT is the most difficult to express to a non-tech audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which metric to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When in doubt, use them all!** \n",
    " -`metrics.classification_report`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.840451Z",
     "start_time": "2021-05-06T15:22:49.831396Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,y_hat_test,target_names=['Died','Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.848828Z",
     "start_time": "2021-05-06T15:22:49.842318Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_hat_test).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **But some good rules of thumb:**\n",
    "    - **Accuracy** is good for non-technical audiences (but can be misleading with imbalanced classes)\n",
    "    \n",
    "    - **Use recall** when the number of true positives/opportunities is small and you don’t want to miss one.\n",
    "        - e.g. cancer diagnosis. (telling someone they do not have cancer when they actually do is fatal)\n",
    "    - **Use precision** when the cost of acting is high and acting on a positive is costly.\n",
    "       - e.g. Allocating resources/interventions for prisoners who are at-risk for recidivism. \n",
    "\n",
    "- **F1 score** is really the most informative about overall model quality, but is the most difficult to express to a non-tech audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT NOTE ABOUT PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn & matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.853132Z",
     "start_time": "2021-05-06T15:22:49.851039Z"
    }
   },
   "outputs": [],
   "source": [
    "#### scikit-learn version\n",
    "## Run COnda List to Verify what versions are installed and how\n",
    "# %conda list scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will need sklearn to be version 0.23 + to have all of the tools covered in lessons.\n",
    "    > Note: sklearn is listed as `scikit-learn`<br>to update: \n",
    "    `conda update scikit-learn`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.858410Z",
     "start_time": "2021-05-06T15:22:49.855842Z"
    }
   },
   "outputs": [],
   "source": [
    "## If have less than 0.23, run this command\n",
    "# %conda update scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.862737Z",
     "start_time": "2021-05-06T15:22:49.860874Z"
    }
   },
   "outputs": [],
   "source": [
    "#### matplotlib version\n",
    "# %conda list matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will want to update matplotlib to fix errors with your confusion matrix plots\n",
    "    > `pip install -U matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:22:49.867126Z",
     "start_time": "2021-05-06T15:22:49.864751Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
