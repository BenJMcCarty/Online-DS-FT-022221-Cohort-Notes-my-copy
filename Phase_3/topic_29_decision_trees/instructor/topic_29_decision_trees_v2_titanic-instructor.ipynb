{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 29: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- onl01-dtsc-ft-022221\n",
    "- 05/11/21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Partitioning Activity\n",
    "- Decision Tree Visual Walkthrough\n",
    "- Entropy and Information Gain\n",
    "- Activity: Decision Trees to Predict Repeat Offender Criminals \n",
    "<!--- - [Hyperparamtere Tuning and Pruning Decision Trees](https://learn.co/tracks/data-science-career-v2/module-5-machine-learning-and-big-data/section-34-decision-trees/hyperparameter-tuning-and-pruning-in-decision-trees-lab)--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/Comments?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:02.969474Z",
     "start_time": "2021-05-11T00:10:01.914104Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format',lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.352871Z",
     "start_time": "2021-05-11T00:10:02.971640Z"
    }
   },
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "from sklearn.datasets import make_blobs\n",
    "np.random.seed(27)\n",
    "plt.style.use(['seaborn-talk'])#,'seaborn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.557171Z",
     "start_time": "2021-05-11T00:10:03.355661Z"
    }
   },
   "outputs": [],
   "source": [
    "f,x = helper_create_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Looking at the example above, would a **vertical** or a **horizontal** cut better split the classes?\n",
    "\n",
    "Also, what threshold should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.561843Z",
     "start_time": "2021-05-11T00:10:03.559536Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'horizontal' or 'vertical'\n",
    "q1_direction = 'vertical'\n",
    "# Between 0 and 10\n",
    "q1_threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.746738Z",
     "start_time": "2021-05-11T00:10:03.563713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer by running this cell\n",
    "f,ax = helper_create_plot()\n",
    "create_line(ax,q1_direction,q1_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **vertical** cut/line would do the best to split with a threshold at about **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.933649Z",
     "start_time": "2021-05-11T00:10:03.748598Z"
    }
   },
   "outputs": [],
   "source": [
    "q1_direction = 'vertical'\n",
    "q1_threshold = 5\n",
    "\n",
    "f,ax = helper_create_plot();\n",
    "create_line(ax,q1_direction, q1_threshold);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Splitting further, what would be the next line & threshold to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:03.938384Z",
     "start_time": "2021-05-11T00:10:03.935972Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'horizontal' or 'vertical'\n",
    "q2_direction = 'horizontal'\n",
    "# Between 0 and 10\n",
    "q2_threshold = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.129889Z",
     "start_time": "2021-05-11T00:10:03.942763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer by running this cell\n",
    "f,ax = helper_create_plot()\n",
    "create_line(ax,q1_direction, q1_threshold)\n",
    "create_line(ax,q2_direction, q2_threshold, x_range=(0, q1_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **horizontal** cut/line would do the best to split with a threshold at about **7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.314323Z",
     "start_time": "2021-05-11T00:10:04.132893Z"
    }
   },
   "outputs": [],
   "source": [
    "q2_direction = 'horizontal'\n",
    "q2_threshold = 7\n",
    "\n",
    "f,ax = helper_create_plot()\n",
    "create_line(ax,q1_direction,q1_threshold)\n",
    "create_line(ax,q2_direction, q2_threshold, x_range=(0, q1_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3:  again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.318485Z",
     "start_time": "2021-05-11T00:10:04.316185Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'horizontal' or 'vertical'\n",
    "q3_direction = 'horizontal'\n",
    "# Between 0 and 10\n",
    "q3_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.506661Z",
     "start_time": "2021-05-11T00:10:04.320292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer by running this cell\n",
    "f,ax = helper_create_plot()\n",
    "create_line(ax, q1_direction, q1_threshold)\n",
    "create_line(ax, q2_direction, q2_threshold, x_range=(0, q1_threshold))\n",
    "create_line(ax, q3_direction, q3_threshold, x_range=(q1_threshold, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **horizontal** cut/line would do the best to split with a threshold at about **1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.750071Z",
     "start_time": "2021-05-11T00:10:04.508923Z"
    }
   },
   "outputs": [],
   "source": [
    "q3_direction = 'horizontal'\n",
    "q3_threshold = 1\n",
    "\n",
    "f,ax = helper_create_plot()\n",
    "create_line(ax, q1_direction, q1_threshold)\n",
    "create_line(ax, q2_direction, q2_threshold, x_range=(0, q1_threshold))\n",
    "create_line(ax, q3_direction, q3_threshold, x_range=(q1_threshold, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **DECISION TREES:**\n",
    "    - Supervised Learning\n",
    "    - Classification OR Regression\n",
    "    - **[Interactive Visual Demonstration](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)**\n",
    "\n",
    "\n",
    "- **ADVANTAGES**\n",
    "    - Interpretability \n",
    "    - Render feature importance\n",
    "    - Less data pre-processing needed\n",
    "    \n",
    "    \n",
    "- **DISADVANTAGES**\n",
    "    - \"Greedy search\" -  short sighted optimization\n",
    "    - Do not predict a continuous output (for regression)\n",
    "    - Does not predict beyond range of the training data\n",
    "    - Overfits SUPER easily\n",
    "\n",
    "<!---<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-intro-to-supervised-learning-online-ds-ft-100719/master/images/new_ml-hierarchy.png\" width=60%>--->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/ex-decision-tree.png\" width=75%>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction Acyclic Graphs (DAG) Definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Direction Acyclic Graph**\n",
    "> A decision tree is a DAG type of classifier where each branch node represents a choice between a number of alternatives and each leaf node represents a classification. An unknown (or test) instance is routed down the tree according to the values of the attributes in the successive nodes. When the instance reaches a leaf, it is classified according to the label assigned to the corresponded leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/jirvingphd/dsc-introduction-to-decision-trees-online-ds-pt-100719/master/images/dt1.png' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy and decision trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision trees aim to tidy the data by separating the samples and re-grouping them in the classes they belong to.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-entropy-and-information-gain-online-ds-ft-100719/master/images/split_fs.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon's Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Entropy is a measure of disorder or uncertainty.__\n",
    "> \n",
    "> The entropy of a variable is the \"amount of information\" contained in the variable. \n",
    ">\n",
    "> - We can informally describe entropy as an indicator of how messy your data is.  A high degree of entropy always reflects \"messed-up\" data with low/no information content. \n",
    "\n",
    "$$\\large H(S) = -\\sum (P_i . log_2(P_i))$$\n",
    "\n",
    "When  $H(S) = 0$, this means that the set $S$ is perfectly classified, meaning that there is no disorganization in our data because all of our data in S is the exact same class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> __Information gain is an impurity/uncertainty based criterion that uses the entropy as the measure of impurity.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$Information~Gain  = Entropy_{parent} - Entropy_{child}.[child ~weighted ~average]$$\n",
    "\n",
    "\n",
    "$$\\large IG(A, S) = H(S) - \\sum{}{p(t)H(t)}  $$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $H(S)$ is the entropy of set $S$\n",
    "* $t$ is a subset of the attributes contained in $A$ (we represent all subsets $t$ as $T$)\n",
    "* $p(t)$ is the proportion of the number of elements in $t$ to the number of elements in $S$\n",
    "* $H(t)$ is the entropy of a given subset $t$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are features and a target (either class or value)\n",
    "\n",
    "\n",
    "2. Train the tree to make a *decision* (a split) about which feature best separates the data, based on some *metric* \n",
    "    - Data are split into partitions/branches\n",
    "    - Metrics include 'Gini Index', 'entropy'\n",
    "    \n",
    "    \n",
    "3. Continue growing each branch of the tree until a stopping criterion is reached.\n",
    "\n",
    "\n",
    "4. Keep doing that until a **stopping condition** is hit.\n",
    "\n",
    "    \n",
    "5. Test the trees decisions using previously unseen data.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-introduction-to-decision-trees-online-ds-ft-100719/master/images/dt3.png\" width=65%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing our data with  `Pipelines` &  `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pipeline Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "\n",
    "\n",
    "- [ColumnTransformer Documentation](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:04.826593Z",
     "start_time": "2021-05-11T00:10:04.752079Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "## New Imports\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.compose import ColumnTransformer,make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.149701Z",
     "start_time": "2021-05-11T00:10:04.828936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the data from 'titanic.csv' and store it in a pandas DataFrame \n",
    "raw_df = pd.read_csv('https://raw.githubusercontent.com/learn-co-curriculum/dsc-knn-with-scikit-learn-lab/master/titanic.csv')\n",
    "raw_df.drop(columns= ['PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
    "            inplace=True)\n",
    "\n",
    "# Print the head of the DataFrame to ensure everything loaded correctly \n",
    "df = raw_df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.159315Z",
     "start_time": "2021-05-11T00:10:05.151771Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get X, y and train-test-split\n",
    "target = 'Survived'\n",
    "\n",
    "X = df.drop(columns=target).copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "## train tst split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.25,\n",
    "                                                    random_state=42)\n",
    "[print(var.shape) for var in [X_train, X_test]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Preprocessing Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since you've done this before, you should be able to do this quite well yourself without much hand holding by now. In the cells below, complete the following steps:\n",
    "1. ~~Remove unnecessary columns (`'PassengerId'`, `'Name'`, `'Ticket'`, and `'Cabin'`) ~~\n",
    "2. Convert `'Sex'` to a binary encoding, where female is `0` and male is `1` \n",
    "3. Detect and deal with any missing values in the dataset:  \n",
    "    * For `'Age'`, replace missing values with the median age for the dataset  \n",
    "    * For `'Embarked'`, drop the rows that contain missing values\n",
    "4. One-hot encode categorical columns such as `'Embarked'` \n",
    "5. Store the target column, `'Survived'`, in a separate variable and remove it from the DataFrame  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Normalizing the data \n",
    "* Import and instantiate `StandardScaler` \n",
    "* Use the scaler's `.fit_transform()` method to create a scaled version of the training dataset  \n",
    "* Use the scaler's `.transform()` method to create a scaled version of the test dataset  \n",
    "* The result returned by `.fit_transform()` and `.transform()` methods will be numpy arrays, not a pandas DataFrame. Create a new pandas DataFrame out of this object called `scaled_df`. To set the column names back to their original state, set the `columns` parameter to `one_hot_df.columns` \n",
    "* Print the head of `scaled_df` to ensure everything worked correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Pipeline for Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.167026Z",
     "start_time": "2021-05-11T00:10:05.161304Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get list of numeric features to sacle\n",
    "num_cols = list(X_train.select_dtypes('number').columns)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.171693Z",
     "start_time": "2021-05-11T00:10:05.169057Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a num_trasnformer pipeline \n",
    "## that will impute using median and then calculate z-scores\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scale',StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.183942Z",
     "start_time": "2021-05-11T00:10:05.173737Z"
    }
   },
   "outputs": [],
   "source": [
    "## Test our num_transformer pipeline .fit_transform X_train\n",
    "num_transformer.fit_transform(X_train[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Pipeline for Categorical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.190851Z",
     "start_time": "2021-05-11T00:10:05.185951Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get list of cat features to encode\n",
    "cat_cols = X_train.select_dtypes('O').columns.tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.196418Z",
     "start_time": "2021-05-11T00:10:05.193519Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a cat_transformer pipeline \n",
    "## that will impute using median and then calculate z-scores\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('encoder',OneHotEncoder(sparse=False,handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.207364Z",
     "start_time": "2021-05-11T00:10:05.198206Z"
    }
   },
   "outputs": [],
   "source": [
    "## Test cat_transformer \n",
    "cat_transformer.fit_transform(X_train[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Putting it all together with `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- [ColumnTransformer Documentation](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.211827Z",
     "start_time": "2021-05-11T00:10:05.209365Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer,make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.243486Z",
     "start_time": "2021-05-11T00:10:05.218410Z"
    }
   },
   "outputs": [],
   "source": [
    "## COMBINE BOTH PIPELINES INTO ONE WITH COLUMN TRANSFORMER\n",
    "preprocessing=ColumnTransformer(transformers=[\n",
    "    ('num',num_transformer,num_cols),\n",
    "    ('cat',cat_transformer,cat_cols)])\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing `preprocessing` Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.293740Z",
     "start_time": "2021-05-11T00:10:05.247757Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.320052Z",
     "start_time": "2021-05-11T00:10:05.296168Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get X_train and X_test from column transformer\n",
    "X_train_tf = preprocessing.fit_transform(X_train)\n",
    "X_test_tf = preprocessing.transform(X_test)\n",
    "X_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Feature Names from our `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.347075Z",
     "start_time": "2021-05-11T00:10:05.322229Z"
    }
   },
   "outputs": [],
   "source": [
    "set_config(display='text')\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.355949Z",
     "start_time": "2021-05-11T00:10:05.348920Z"
    }
   },
   "outputs": [],
   "source": [
    "## Explore the named_transformers\n",
    "preprocessing.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.363645Z",
     "start_time": "2021-05-11T00:10:05.358520Z"
    }
   },
   "outputs": [],
   "source": [
    "## Slice out the 'cat' transformer and inspect .named_steps\n",
    "preprocessing.named_transformers_['cat'].named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.369082Z",
     "start_time": "2021-05-11T00:10:05.365397Z"
    }
   },
   "outputs": [],
   "source": [
    "## Slice out the 'encoder' from the cat transformers' named_steps\n",
    "preprocessing.named_transformers_['cat'].named_steps['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.375069Z",
     "start_time": "2021-05-11T00:10:05.370861Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use the encoder's .get_feature_names\n",
    "feature_names = preprocessing.named_transformers_['cat'].\\\n",
    "                named_steps['encoder'].get_feature_names(cat_cols).tolist()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.381714Z",
     "start_time": "2021-05-11T00:10:05.377042Z"
    }
   },
   "outputs": [],
   "source": [
    "## Find the encoder inside the cat transformer\n",
    "X_cols = num_cols+feature_names\n",
    "X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.386556Z",
     "start_time": "2021-05-11T00:10:05.383500Z"
    }
   },
   "outputs": [],
   "source": [
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.391728Z",
     "start_time": "2021-05-11T00:10:05.388151Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.431502Z",
     "start_time": "2021-05-11T00:10:05.394082Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fit preprocessing pipeline and pull out the feature names and X_cols\n",
    "preprocessing.fit(X_train)\n",
    "feature_names = list(preprocessing.named_transformers_['cat'].\\\n",
    "                named_steps['encoder'].get_feature_names(cat_cols))\n",
    "X_cols = num_cols+feature_names\n",
    "\n",
    "\n",
    "## Tranform X_train and X_test and make into DataFrames\n",
    "X_train_df = pd.DataFrame(preprocessing.transform(X_train),columns=X_cols,\n",
    "                          index=X_train.index)\n",
    "X_test_df = pd.DataFrame(preprocessing.transform(X_test),columns=X_cols,\n",
    "                         index=X_test.index)\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.468292Z",
     "start_time": "2021-05-11T00:10:05.433268Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DecisionTreeClassifier` with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.489693Z",
     "start_time": "2021-05-11T00:10:05.469988Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "## Imports for visualizing trees\n",
    "from sklearn.tree import plot_tree,export_graphviz\n",
    "from IPython.display import Image  \n",
    "from pydotplus import graph_from_dot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions from Prior Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.645800Z",
     "start_time": "2021-05-11T00:10:37.580031Z"
    }
   },
   "outputs": [],
   "source": [
    "## Modified version of our simple eval function from Topic 25 Part 2 Study Group\n",
    "# - Added X_train and y_train for if we want scores for both train and test\n",
    "def evaluate_classification(model, X_test_tf,y_test,cmap='Reds',\n",
    "                            normalize='true',classes=None,figsize=(10,4),\n",
    "                            X_train = None, y_train = None,):\n",
    "    \"\"\"Evaluates a scikit-learn binary classification model.\n",
    "\n",
    "    Args:\n",
    "        model ([type]): [description]\n",
    "        X_test_tf ([type]): [description]\n",
    "        y_test ([type]): [description]\n",
    "        cmap (str, optional): [description]. Defaults to 'Reds'.\n",
    "        normalize (str, optional): [description]. Defaults to 'true'.\n",
    "        classes ([type], optional): [description]. Defaults to None.\n",
    "        figsize (tuple, optional): [description]. Defaults to (8,4).\n",
    "        X_train ([type], optional): [description]. Defaults to None.\n",
    "        y_train ([type], optional): [description]. Defaults to None.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    y_hat_test = model.predict(X_test_tf)\n",
    "    print(metrics.classification_report(y_test, y_hat_test,target_names=classes))\n",
    "    \n",
    "    fig,ax = plt.subplots(ncols=2,figsize=figsize)\n",
    "    metrics.plot_confusion_matrix(model, X_test_tf,y_test,cmap=cmap, \n",
    "                                  normalize=normalize,display_labels=classes,\n",
    "                                 ax=ax[0])\n",
    "    \n",
    "    curve = metrics.plot_roc_curve(model,X_test_tf,y_test,ax=ax[1])\n",
    "    curve.ax_.grid()\n",
    "    curve.ax_.plot([0,1],[0,1],ls=':')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    ## Add comparing Scores if X_train and y_train provided.\n",
    "    if (X_train is not None) & (y_train is not None):\n",
    "        print(f\"Training Score = {model.score(X_train,y_train):.2f}\")\n",
    "        print(f\"Test Score = {model.score(X_test_tf,y_test):.2f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def evaluate_grid(grid,X_test,y_test,X_train=None,y_train=None):\n",
    "    print('The best parameters were:')\n",
    "    print(\"\\t\",grid.best_params_)\n",
    "    \n",
    "    model = grid.best_estimator_    \n",
    "\n",
    "    print('\\n[i] Classification Report')\n",
    "    evaluate_classification(model, X_test,y_test,X_train=X_train,y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla DecisionTree (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.578335Z",
     "start_time": "2021-05-11T00:10:37.570146Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create, fit, and evaluate a vanilla DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train_df,y_train)\n",
    "tree.score(X_train_df,y_train)\n",
    "\n",
    "## Evaluate\n",
    "evaluate_classification(tree,X_test_df,y_test,X_train=X_train_df,\n",
    "                       y_train=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.735320Z",
     "start_time": "2021-05-11T00:10:05.731796Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check out feature importances\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.741760Z",
     "start_time": "2021-05-11T00:10:05.737225Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make into a series\n",
    "importance = pd.Series(clf.feature_importances_, X_train_df.columns)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:05.933193Z",
     "start_time": "2021-05-11T00:10:05.743865Z"
    }
   },
   "outputs": [],
   "source": [
    "## sort values and plot kind='barh'\n",
    "importance.sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:20.273190Z",
     "start_time": "2021-05-11T00:10:05.935334Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot_tree from sklearn\n",
    "fig,ax = plt.subplots(figsize=(60,25))\n",
    "plot_tree(clf,filled=True,rounded=True,proportion=True,\n",
    "          feature_names=X_train_df.columns,\n",
    "          class_names=['Died','Survived'],ax=ax);\n",
    "fig.tight_layout()\n",
    "# fig.savefig('titanic_tree.pdf', dpi=300,orientation='landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.559118Z",
     "start_time": "2021-05-11T00:10:20.274691Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_tree(clf,figsize=(60,25),class_names=['Died','Survived'],\n",
    "              savefig=False,fname='titanic_tree.pdf'):\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    plot_tree(clf,filled=True,rounded=True,proportion=True,\n",
    "              feature_names=X_train_df.columns,\n",
    "              class_names=class_names,ax=ax);\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if savefig:\n",
    "        fig.savefig(fname, dpi=300,orientation='landscape')\n",
    "        \n",
    "show_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter Tuning - Pruning Our Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla DecisionTree (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.578335Z",
     "start_time": "2021-05-11T00:10:37.570146Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train_df,y_train)\n",
    "tree.score(X_train_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:38.063775Z",
     "start_time": "2021-05-11T00:10:37.648101Z"
    }
   },
   "outputs": [],
   "source": [
    "## Evaluate\n",
    "evaluate_classification(tree,X_test_df,y_test,X_train=X_train_df,\n",
    "                       y_train=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:38.071877Z",
     "start_time": "2021-05-11T00:10:38.066052Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_importances(tree):\n",
    "df_import = pd.Series(tree.feature_importances_, \n",
    "                      index = X_train_df.columns,name='Importance')\n",
    "df_import.sort_values(inplace=True)\n",
    "df_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:38.253617Z",
     "start_time": "2021-05-11T00:10:38.074441Z"
    }
   },
   "outputs": [],
   "source": [
    "df_import.tail(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:38.459791Z",
     "start_time": "2021-05-11T00:10:38.256140Z"
    }
   },
   "outputs": [],
   "source": [
    "## Combine into a function\n",
    "def plot_importance(tree, X_train_df, top_n=20,figsize=(10,10)):\n",
    "    df_importance = pd.Series(tree.feature_importances_,index=X_train_df.columns)\n",
    "    df_importance.sort_values(ascending=True).tail(top_n).plot(\n",
    "        kind='barh',figsize=figsize,title='Feature Importances',\n",
    "    ylabel='Feature',)\n",
    "    return df_importance\n",
    "plot_importance(tree,X_train_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning our DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "- Useful to consider to make sure you don't overfit or underfit\n",
    "\n",
    "Check out the scikit-learn documentation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max-depth`\n",
    "- `min_samples_leaf`: The smallest number of samples that can be in a leaf (node)\n",
    "- `min_samples_split`: The smallest number of samples in a leaf (node) before splitting it\n",
    "- `max_features`: Most features to consider when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:41.665296Z",
     "start_time": "2021-05-11T00:10:38.462028Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Set up param grid\n",
    "params = {'max_depth':[None,5,10,20,25],\n",
    "         'class_weight':[None, 'balanced']}\n",
    "\n",
    "## Instantiate & Fit GridSearchCV\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,n_jobs=-1)\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:42.161189Z",
     "start_time": "2021-05-11T00:10:41.668007Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try scoring='recall'\n",
    "\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,cv=3,n_jobs=-1,\n",
    "                          scoring='recall')\n",
    "## Fit searchc\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:42.665618Z",
     "start_time": "2021-05-11T00:10:42.162874Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try scoring='recall_macro'\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,cv=3,\n",
    "                          n_jobs=-1,scoring='recall_macro')\n",
    "## Fit searchc\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:43.236924Z",
     "start_time": "2021-05-11T00:10:42.668069Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try scoring='f1'\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,cv=3,\n",
    "                          n_jobs=-1,scoring='f1')\n",
    "## Fit searchc\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:43.708367Z",
     "start_time": "2021-05-11T00:10:43.238654Z"
    }
   },
   "outputs": [],
   "source": [
    "## Try scoring='f1'\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,cv=3,\n",
    "                          n_jobs=-1,scoring='f1_macro')\n",
    "## Fit searchc\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning More Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:43.714671Z",
     "start_time": "2021-05-11T00:10:43.710306Z"
    }
   },
   "outputs": [],
   "source": [
    "[1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:44.568918Z",
     "start_time": "2021-05-11T00:10:43.716614Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Set up param grid\n",
    "params = {'max_depth':[None,5,10,15,20,25],\n",
    "         'class_weight':[None, 'balanced'],\n",
    "         'min_samples_leaf':[1,3,5],\n",
    "         'criterion':['gini','entropy']}\n",
    "\n",
    "## Instantiate & Fit GridSearchCV\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(),params,n_jobs=-1,\n",
    "                          scoring='recall_macro')\n",
    "gridsearch.fit(X_train_df,y_train)\n",
    "\n",
    "## Evaluate with our function\n",
    "evaluate_grid(gridsearch,X_test_df,y_test, X_train=X_train_df, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:44.572427Z",
     "start_time": "2021-05-11T00:10:44.570709Z"
    }
   },
   "outputs": [],
   "source": [
    "# gridsearch.best_estimator_.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Trees with Graphviz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what rules the tree learned by plotting this decision tree. To do this, you need to use additional packages such as `pytdotplus`. \n",
    "\n",
    "> **Note:** If you are run into errors while generating the plot, you probably need to install `python-graphviz` in your machine using `conda install python-graphviz`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE ON INSTALLING GRAPHVIZ:\n",
    "- On windows you must [download the Graphviz installer](https://www.graphviz.org/download/)(Choose the \"stable\" release), install it, and then add the `bin` folder inside of it to your system's Path.\n",
    "- [To Edit your path on MaC](https://www.architectryan.com/2012/10/02/add-to-the-path-on-mac-os-x-mountain-lion/)\n",
    "\n",
    "- [TO Edit Your Path on Windows (10)](https://www.architectryan.com/2018/03/17/add-to-the-path-on-windows-10/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.562598Z",
     "start_time": "2021-05-11T00:10:37.560761Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create DOT data\n",
    "# dot_data = export_graphviz(clf, out_file=None, \n",
    "#                            feature_names=X_train_df.columns,  \n",
    "#                            class_names=['No Game','Play Game'],#np.unique(y).astype('str'), \n",
    "#                            filled=True, rounded=True,proportion=True,\n",
    "#                            special_characters=True)\n",
    "\n",
    "# # Draw graph\n",
    "# graph = graph_from_dot_data(dot_data)  \n",
    "\n",
    "# # Show graph\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.565831Z",
     "start_time": "2021-05-11T00:10:37.564090Z"
    }
   },
   "outputs": [],
   "source": [
    "# def viz_tree(clf,X_train_df,y):\n",
    "#     # Create DOT data\n",
    "#     dot_data = export_graphviz(clf, out_file=None, \n",
    "#                                feature_names=X_train_df.columns,  \n",
    "#                                class_names=np.unique(y).astype('str'), \n",
    "#                                filled=True, rounded=True,#proportion=True,\n",
    "#                                special_characters=True)\n",
    "\n",
    "#     # Draw graph\n",
    "#     graph = graph_from_dot_data(dot_data)  \n",
    "\n",
    "#     # Show graph\n",
    "#     return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:37.568856Z",
     "start_time": "2021-05-11T00:10:37.567102Z"
    }
   },
   "outputs": [],
   "source": [
    "# viz_tree(clf,X_train_df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Our Models So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:44.576778Z",
     "start_time": "2021-05-11T00:10:44.574631Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDRESSING IMBALANCED CLASSES\n",
    "\n",
    "- Downsample/undersampling to match minority class.\n",
    "- Synthetic Minority Over Sampling Technique (SMOTE)\n",
    "-  Adaptive Synthetic (ADASYN)\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/Flashcards/Downsampling_web.png\" width=10%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:44.584653Z",
     "start_time": "2021-05-11T00:10:44.578133Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check class\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:48.602487Z",
     "start_time": "2021-05-11T00:10:48.594465Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_res, y_train_res = smote.fit_sample(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:50.213982Z",
     "start_time": "2021-05-11T00:10:50.209355Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train_res).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:11:15.799689Z",
     "start_time": "2021-05-11T00:11:15.281065Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()#max_depth=5)\n",
    "\n",
    "tree.fit(X_train_res,y_train_res)\n",
    "print('Training Score:',tree.score(X_train_res,y_train_res))\n",
    "evaluate_classification(tree, X_test_df,y_test,X_train=X_train_df,y_train=y_train)\n",
    "\n",
    "plot_importance(tree,X_train_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T00:10:45.576975Z",
     "start_time": "2021-05-11T00:10:45.295967Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_tree(tree,show=False,feature_names=X_train_tf.columns,save_filename='big_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
