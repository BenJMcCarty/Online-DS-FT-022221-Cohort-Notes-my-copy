{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topic 30: Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- onl01-dtsc-ft-022221\n",
    "- 05/12/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Discuss the various types of ensembles methods\n",
    "- Compare and contrast them and their advantages/disadvantages\n",
    "\n",
    "- Activity: Mini-Project on Iowa Prisoner Recividism \n",
    "    - Baseline models\n",
    "    - Apply various ensemble methods.\n",
    "    - Review dealing with imbalanced classes\n",
    "    - GridSearchCV\n",
    "    \n",
    "\n",
    "- Quick overview of non-gridsearch cross-validation + saving models. (If there's time)\n",
    "    - `Notes rep` > `Phase_3` > `scratch_notebooks` > `topic_29_decision_trees_v2-with_crossval_model_saving.ipynb` (look for the header with a ⭐️)\n",
    "    - Also in the Appendix at the bottom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ensemble Methods: Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> ***Ensemble Methods take advantage of the delphic technique (or \"wisdom of crowds\") where the average of multiple independent estimates is usually more consistently accurate than the individual estimates.***\n",
    "\n",
    "\n",
    "#### Types of Ensembles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Bootstrap Aggregation (Bagging)\n",
    "    - Bagging Classifier\n",
    "    - Random Forests\n",
    "- Gradient Boosting:\n",
    "    - Adaboost\n",
    "    - Gradient Boosted Trees\n",
    "    - XGBoost\n",
    "- Model Stacking A.K.K. Meta-Ensembling\n",
    "    - VotingClassifer\n",
    "    - StackingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bootstrap Aggregation (Bagging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/Flashcards/Bagging_web.png\">\n",
    "The process for training an ensemble through bootstrap aggregation is as follows:\n",
    "\n",
    "1. Grab a sizable sample from your dataset, with replacement \n",
    "2. Train a classifier on this sample  \n",
    "3. Repeat until all classifiers have been trained on their own sample from the dataset  \n",
    "4. When making a prediction, have each classifier in the ensemble make a prediction \n",
    "5. Aggregate all predictions from all classifiers into a single prediction, using the method of your choice  \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-ensemble-methods-online-ds-ft-100719/master/images/new_bagging.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/Flashcards/Random_Forest_web.png\">\n",
    "\n",
    "- Because decision trees are greedy algorithms, every tree given same data would make same conclusions.\n",
    "- **In addition to bagging**, random forests use **subspace sampling**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-random-forests-online-ds-ft-100719/master/images/new_rf-diagram.png\" width=70%>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Benefits and drawbacks\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "* **_Strong performance_** Because this is an ensemble algorithm, the model is naturally resistant to noise and variance in the data, and generally tends to perform quite well. \n",
    "\n",
    "* **_Interpretability_**:  each tree in the random forest is a **_Glass-Box Model_** (meaning that the model is interpretable, allowing us to see how it arrived at a certain decision), the overall random forest is, as well! \n",
    "\n",
    "#### Drawbacks\n",
    "\n",
    "* **_Computational complexity_**: On large datasets, the runtime can be quite slow compared to other algorithms.\n",
    "\n",
    "* **_Memory usage_**: Random forests tend to have a larger memory footprint that other models. It's not uncommon to see random forests that were trained on large datasets have memory footprints in the tens, or even hundreds of MB. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Boosting / Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Weak learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All the models we've learned so far are **_Strong Learners_** -- models with the goal of doing as well as possible on the classification or regression task they are given. \n",
    "\n",
    "The term **_Weak Learner_** refers to simple models that do only slightly better than random chance. \n",
    "\n",
    "Boosting algorithms start with a single weak learner (usually trees), but technically, any model will do. \n",
    "\n",
    "Boosting works as follows:\n",
    "\n",
    "1. Train a single weak learner  \n",
    "2. Figure out which examples the weak learner got wrong  \n",
    "3. Build another weak learner that focuses on the areas the first weak learner got wrong  \n",
    "4. Continue this process until a predetermined stopping condition is met, such as until a set number of weak learners have been created, or the model's performance has plateaued  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Adaboost & Gradient Boosted Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Adaboost (Adaptive Boosting)\n",
    "\n",
    "- **_Key Takeaway:_** Adaboost creates new classifiers by continually influencing the distribution of the data sampled to train each successive learner. \n",
    "- Uses subsampling with **weighted-probabilities for incorrect predictions to be included in subsequent weak learner**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-gradient-boosting-and-weak-learners/master/images/new_adaboost.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Gradient Boosted Trees\n",
    "- More advanced form - uses gradient descent.\n",
    "- Trains successive trees on the **residuals**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-gradient-boosting-and-weak-learners-online-ds-ft-100719/master/images/new_gradient-boosting.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Differences between Gradient Boosting and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Independent vs iterative\n",
    "    - in Random Forests one tree is unaffacted by another.\n",
    "    - in Boosting mode each tree is iteratively created to address the prior tree's weaknesses.\n",
    "    \n",
    "- Weak vs Strong\n",
    "\n",
    "    - In a random forest, each tree is a strong learner -- they would do just fine as a decision tree on their own.\n",
    "    - In boosting algorithms, trees are artificially limited to a very shallow depth (usually only 1 split) \n",
    "        - to ensure that **each model is only slightly better than random chance**. \n",
    "\n",
    "- Aggregate Predictions:\n",
    "    - in RF each tree votes\n",
    "    - in boosting models trees are given weight for being good at \"hard tasks\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modeling Stacking / Meta-Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Model stacking is when you use the predictions of one model as the input to another model.\n",
    "<img src=\"https://burakhimmetoglu.files.wordpress.com/2016/12/workflow.png?w=1140\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Activity: Predicting Recidivism in Iowa Prisoners "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Iowa has a major problem with recidivism,  where ~38% of all inmates released from prison wind up back in jail after returning to a life of crime (AKA recidivism).\n",
    "- Dataset contains information on released prisoners and if they returned to prison within 3 years of being release. \n",
    "    - Dataset can be [found on Kaggle](https://www.kaggle.com/slonnadube/recidivism-for-offenders-released-from-prison), which was extracted from [Iowa's data portal](https://data.iowa.gov/Correctional-System/3-Year-Recidivism-for-Offenders-Released-from-Pris/mw8r-vqy4). \n",
    "\n",
    "- We will be using a partially pre-processed version of the dataset (columns have been renamed/simplified).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/LSA_map_with_counties_districts_and_B54A5BBCE4156.jpg\" width=50%> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:17.423368Z",
     "start_time": "2021-05-12T15:27:15.766730Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:22.913382Z",
     "start_time": "2021-05-12T15:27:17.425344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# raw_data = 'https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/datasets/FULL_3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv'\n",
    "renamed_data = 'https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/datasets/Iowa_Prisoners_Renamed_Columns_fsds_100719.csv'\n",
    "df = pd.read_csv(renamed_data,index_col=0)\n",
    "\n",
    "## Drop unwanted cols using year\n",
    "df = df.drop(columns=['yr_released','report_year'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:22.932390Z",
     "start_time": "2021-05-12T15:27:22.915621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## SCRUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Null values (fill or drop)\n",
    "- Data Types (finding categorical variables)\n",
    "- Inspect the value_counts/labels of categoricals\n",
    "- Scaling or lack-off\n",
    "- One hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.484339Z",
     "start_time": "2021-05-12T15:27:22.934571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Check null values\n",
    "import missingno\n",
    "missingno.matrix(df)\n",
    "plt.show()\n",
    "null_check = pd.DataFrame({\n",
    "    '#null':df.isna().sum(),\n",
    "    '%null':round(df.isna().sum()/len(df)*100,2)\n",
    "})\n",
    "null_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.558199Z",
     "start_time": "2021-05-12T15:27:23.509013Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## inspect categories\n",
    "dashes = '---'*20\n",
    "for col in df.columns:\n",
    "    print(dashes)\n",
    "    print(f\"Value Counts for {col}:\")\n",
    "    display(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `race_ethnicity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.566439Z",
     "start_time": "2021-05-12T15:27:23.559509Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['race_ethnicity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> - Simplify race and ethnicity down to race\n",
    "    - (also tried separating race and ethnicity and using as 2 separate features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.583250Z",
     "start_time": "2021-05-12T15:27:23.570885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Defining Dictionary Map for race_ethnicity categories\n",
    "race_ethnicity_map = {'White - Non-Hispanic':'White',\n",
    "                        'Black - Non-Hispanic': 'Black',\n",
    "                        'White - Hispanic' : 'Hispanic',\n",
    "                        'American Indian or Alaska Native - Non-Hispanic' : 'American Native',\n",
    "                        'Asian or Pacific Islander - Non-Hispanic' : 'Asian or Pacific Islander',\n",
    "                        'Black - Hispanic' : 'Black',\n",
    "                        'American Indian or Alaska Native - Hispanic':'American Native',\n",
    "                        'White -' : 'White',\n",
    "                        'Asian or Pacific Islander - Hispanic' : 'Asian or Pacific Islander',\n",
    "                        'N/A -' : np.nan,\n",
    "                        'Black -':'Black'}\n",
    "\n",
    "df['race'] = df['race_ethnicity'].map(race_ethnicity_map)\n",
    "df['race'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `crime_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.593596Z",
     "start_time": "2021-05-12T15:27:23.586432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['crime_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> After some research, we found that several of the less-frequent classes were actually equivalent to other classes. (e.g. 'Special Sentence 2005' -> 'Sex Offender',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.607929Z",
     "start_time": "2021-05-12T15:27:23.595771Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remapping\n",
    "crime_class_map = {'Other Felony (Old Code)': np.nan ,#or other felony\n",
    "                  'Other Misdemeanor':np.nan,\n",
    "                   'Felony - Mandatory Minimum':np.nan, # if minimum then lowest sentence ==  D Felony\n",
    "                   'Special Sentence 2005': 'Sex Offender',\n",
    "                   'Other Felony' : np.nan ,\n",
    "                   'Sexual Predator Community Supervision' : 'Sex Offender',\n",
    "                   'D Felony': 'D Felony',\n",
    "                   'C Felony' :'C Felony',\n",
    "                   'B Felony' : 'B Felony',\n",
    "                   'A Felony' : 'A Felony',\n",
    "                   'Aggravated Misdemeanor':'Aggravated Misdemeanor',\n",
    "                   'Felony - Enhancement to Original Penalty':'Felony - Enhanced',\n",
    "                   'Felony - Enhanced':'Felony - Enhanced' ,\n",
    "                   'Serious Misdemeanor':'Serious Misdemeanor',\n",
    "                   'Simple Misdemeanor':'Simple Misdemeanor'}\n",
    "\n",
    "df['crime_class'] = df['crime_class'].map(crime_class_map)\n",
    "df['crime_class'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `age_released`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.616866Z",
     "start_time": "2021-05-12T15:27:23.609618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['age_released'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.620691Z",
     "start_time": "2021-05-12T15:27:23.618660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Encoding age groups as ordinal\n",
    "# age_ranges = ('Under 25','25-34', '35-44','45-54','55 and Older')\n",
    "# age_codes = (0,1,2,3,4) \n",
    "# # Zipping into Dictionary to Map onto Column\n",
    "# age_map = dict(zip(age_ranges,age_codes))\n",
    "# age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.624149Z",
     "start_time": "2021-05-12T15:27:23.622259Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df['age_enc'] = df['age_released'].map(age_map)\n",
    "# df['age_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.629887Z",
     "start_time": "2021-05-12T15:27:23.625768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Mapping age_map onto 'age_released'\n",
    "# Encoding age groups as ordinal\n",
    "age_ranges = ('Under 25','25-34', '35-44','45-54','55 and Older')\n",
    "age_numbers = (20,30,40,50,65) \n",
    "\n",
    "age_num_map = dict(zip(age_ranges,age_numbers))\n",
    "age_num_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.641379Z",
     "start_time": "2021-05-12T15:27:23.631640Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['age_number'] = df['age_released'].map(age_num_map)\n",
    "df['age_number'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.645311Z",
     "start_time": "2021-05-12T15:27:23.643137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## saving list of features thaat have been replaced wiht engineered nes\n",
    "drop_cols = ['age_released','race_ethnicity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## EXPLORE (super-brief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.808798Z",
     "start_time": "2021-05-12T15:27:23.647351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Visualzie class balance\n",
    "sns.countplot(data=df,x='recidivist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.812796Z",
     "start_time": "2021-05-12T15:27:23.810552Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sns.catplot(data=df, x='age_number',hue='recidivist',kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:23.946330Z",
     "start_time": "2021-05-12T15:27:23.814862Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['recidivist'].map({'Yes':1,\"No\":0})\n",
    "X = df.drop(columns=['recidivist',*drop_cols])\n",
    "\n",
    "## Train test split\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=3210)#,stratify=y)\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Pipelnes and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.012054Z",
     "start_time": "2021-05-12T15:27:23.948303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.025596Z",
     "start_time": "2021-05-12T15:27:24.014031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.029869Z",
     "start_time": "2021-05-12T15:27:24.027480Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.045084Z",
     "start_time": "2021-05-12T15:27:24.036699Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## saving list of numeric vs categorical feature\n",
    "num_cols = list(X_train.select_dtypes('number').columns)\n",
    "cat_cols = list(X_train.select_dtypes('object').columns)\n",
    "num_cols,cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.088325Z",
     "start_time": "2021-05-12T15:27:24.048885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## create pipelines and column transformer\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "#     ('scale',StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='MISSING')),\n",
    "    ('encoder',OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "## COMBINE BOTH PIPELINES INTO ONE WITH COLUMN TRANSFORMER\n",
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('num',num_transformer,num_cols),\n",
    "    ('cat',cat_transformer,cat_cols)])\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.243524Z",
     "start_time": "2021-05-12T15:27:24.090707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Fit preprocessing pipeline on training data and pull out the feature names and X_cols\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "## Use the encoder's .get_feature_names\n",
    "cat_features = list(preprocessor.named_transformers_['cat'].named_steps['encoder']\\\n",
    "                            .get_feature_names(cat_cols))\n",
    "X_cols = num_cols+cat_features\n",
    "\n",
    "## Transform X_traian,X_test and remake dfs\n",
    "X_train_df = pd.DataFrame(preprocessor.transform(X_train),\n",
    "                          index=X_train.index, columns=X_cols)\n",
    "X_test_df = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                          index=X_test.index, columns=X_cols)\n",
    "\n",
    "## Tranform X_train and X_test and make into DataFrames\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Functions from Prior Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.266534Z",
     "start_time": "2021-05-12T15:27:24.245349Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Write a fucntion to evalute the model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import plot_tree\n",
    "## Modified version of our simple eval function from Topic 25 Part 2 Study Group\n",
    "# - Added X_train and y_train for if we want scores for both train and test\n",
    "def evaluate_classification(model, X_test_tf,y_test,cmap='Greens',\n",
    "                            normalize='true',classes=None,figsize=(10,4),\n",
    "                            X_train = None, y_train = None,):\n",
    "    \"\"\"Evaluates a scikit-learn binary classification model.\n",
    "\n",
    "    Args:\n",
    "        model (classifier): any sklearn classification model.\n",
    "        X_test_tf (Frame or Array): X data\n",
    "        y_test (Series or Array): y data\n",
    "        cmap (str, optional): Colormap for confusion matrix. Defaults to 'Greens'.\n",
    "        normalize (str, optional): normalize argument for plot_confusion_matrix. \n",
    "                                    Defaults to 'true'.\n",
    "        classes (list, optional): List of class names for display. Defaults to None.\n",
    "        figsize (tuple, optional): figure size Defaults to (8,4).\n",
    "        \n",
    "        X_train (Frame or Array, optional): If provided, compare model.score \n",
    "                                for train and test. Defaults to None.\n",
    "        y_train (Series or Array, optional): If provided, compare model.score \n",
    "                                for train and test. Defaults to None.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    y_hat_test = model.predict(X_test_tf)\n",
    "    print(metrics.classification_report(y_test, y_hat_test,target_names=classes))\n",
    "    \n",
    "    fig,ax = plt.subplots(ncols=2,figsize=figsize)\n",
    "    metrics.plot_confusion_matrix(model, X_test_tf,y_test,cmap=cmap, \n",
    "                                  normalize=normalize,display_labels=classes,\n",
    "                                 ax=ax[0])\n",
    "    \n",
    "    curve = metrics.plot_roc_curve(model,X_test_tf,y_test,ax=ax[1])\n",
    "    curve.ax_.grid()\n",
    "    curve.ax_.plot([0,1],[0,1],ls=':')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    ## Add comparing Scores if X_train and y_train provided.\n",
    "    if (X_train is not None) & (y_train is not None):\n",
    "        print(f\"Training Score = {model.score(X_train,y_train):.2f}\")\n",
    "        print(f\"Test Score = {model.score(X_test_tf,y_test):.2f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def evaluate_grid(grid,X_test,y_test,X_train=None,y_train=None):\n",
    "    print('The best parameters were:')\n",
    "    print(\"\\t\",grid.best_params_)\n",
    "    \n",
    "    model = grid.best_estimator_    \n",
    "\n",
    "    print('\\n[i] Classification Report')\n",
    "    evaluate_classification(model, X_test,y_test,X_train=X_train,y_train=y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_importance(tree, X_train_df, top_n=20,figsize=(10,10)):\n",
    "    \n",
    "    df_importance = pd.Series(tree.feature_importances_,\n",
    "                              index=X_train_df.columns)\n",
    "    df_importance.sort_values(ascending=True).tail(top_n).plot(\n",
    "        kind='barh',figsize=figsize,title='Feature Importances',\n",
    "    ylabel='Feature',)\n",
    "    return df_importance\n",
    "\n",
    "\n",
    "\n",
    "def show_tree(clf,figsize=(60,25),class_names=['Died','Survived'],\n",
    "              savefig=False,fname='titanic_tree.pdf',max_depth=None,):\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    plot_tree(clf,filled=True,rounded=True,proportion=True,\n",
    "              feature_names=X_train_df.columns,\n",
    "              class_names=class_names,ax=ax);\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if savefig:\n",
    "        fig.savefig(fname, dpi=300,orientation='landscape')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Baseline Model (DummyClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:24.639352Z",
     "start_time": "2021-05-12T15:27:24.268834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "clf.fit(X_train_df,y_train)\n",
    "evaluate_classification(clf,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Q: What do we notice about the results of our dummy classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Vanilla DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:25.097352Z",
     "start_time": "2021-05-12T15:27:24.641229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(class_weight='balanced')\n",
    "tree.fit(X_train_df,y_train)\n",
    "evaluate_classification(tree,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:25.102334Z",
     "start_time": "2021-05-12T15:27:25.099494Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# how deep is tree?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:25.374696Z",
     "start_time": "2021-05-12T15:27:25.103845Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Check feature importance\n",
    "importances = plot_importance(tree,X_train_df,top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:25.377781Z",
     "start_time": "2021-05-12T15:27:25.375892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show_tree(tree,savefig=True,fname='prisoners_tree.pdf',max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- `max-depth`\n",
    "- `min_samples_leaf`: The smallest number of samples that can be in a leaf (node)\n",
    "- `min_samples_split`: The smallest number of samples in a leaf (node) before splitting it\n",
    "- `max_features`: Most features to consider when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:58.027078Z",
     "start_time": "2021-05-12T15:27:25.379280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "## Instantiate classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "## Set up param grid\n",
    "param_grid = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[None, 5,10,15,20],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'class_weight':['balanced'],\n",
    "             'max_features':['auto',10,30,70,None]}\n",
    "\n",
    "## Instantiate GridSearchCV\n",
    "grid_clf = GridSearchCV(tree,param_grid,scoring='f1_macro')\n",
    "grid_clf.fit(X_train_df,y_train)\n",
    "evaluate_grid(grid_clf,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:58.030597Z",
     "start_time": "2021-05-12T15:27:58.028750Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Instantiate GridSearchCV\n",
    "grid_clf = GridSearchCV(tree,param_grid,scoring='recall_macro')\n",
    "grid_clf.fit(X_train_df,y_train)\n",
    "evaluate_grid(grid_clf,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:27:59.456084Z",
     "start_time": "2021-05-12T15:27:58.033248Z"
    },
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Import bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "## Fit Classifier and get predictions\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train_df,y_train)\n",
    "evaluate_classification(bag,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:38:17.137096Z",
     "start_time": "2020-04-11T00:38:15.965034Z"
    },
    "hidden": true
   },
   "source": [
    "### ✍️ Dealing with Class Imbalance with encoded feature via `SMOTENC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:38:17.137096Z",
     "start_time": "2020-04-11T00:38:15.965034Z"
    },
    "hidden": true
   },
   "source": [
    "- AKA when there's no `class_weight` argument and you have one hot encoded features\n",
    "\n",
    "#### SMOTENC is another SMOTE class from imblearn\n",
    "- https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html\n",
    "- It is designed for categorical features. \n",
    "- It needs a list of True/False for every feature (True=one hot encoded, False=numerical)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:32:42.621198Z",
     "start_time": "2021-05-12T15:32:41.915971Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:32:39.133516Z",
     "start_time": "2021-05-12T15:32:39.130808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Save list of trues and falses for each col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Retrain BaggingClassifer on resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:04.489994Z",
     "start_time": "2021-05-12T15:28:02.736455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train_sm,y_train_sm)\n",
    "evaluate_classification(bag,X_test_df,y_test,X_train=X_train_sm,y_train =y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:07.522301Z",
     "start_time": "2021-05-12T15:28:04.491726Z"
    },
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Import Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Fit Random Forest\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf.fit(X_train_df, y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## get feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:11.816141Z",
     "start_time": "2021-05-12T15:28:07.524421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Try using smote instead of class_weight\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "evaluate_classification(rf,X_test_df,y_test,X_train=X_train_sm,y_train =y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ExtraTrees Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Instead of always choosing the *optimal* branching path, we  choose a branching path at random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:15.659376Z",
     "start_time": "2021-05-12T15:28:11.817804Z"
    },
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Import and fit an ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etrees = ExtraTreesClassifier(class_weight='balanced')\n",
    "etrees.fit(X_train_df, y_train)\n",
    "evaluate_classification(etrees,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> \"`XGBoost` is a stand-alone library that implements popular gradient boosting algorithms in the fastest, most performant way possible. There are many under-the-hood optimizations that allow XGBoost to train more quickly than any other library implementations of gradient boosting algorithms:\n",
    "- For instance, XGBoost is configured in such a way that it parallelizes the construction of trees across all your computer's CPU cores during the training phase. \n",
    "- It also allows for more advanced use cases, such as distributing training across a cluster of computers, which is often a technique used to speed up computation. \n",
    "- The algorithm even automatically handles missing values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:15.829927Z",
     "start_time": "2021-05-12T15:28:15.661215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## import xgboost RF\n",
    "from xgboost import XGBRFClassifier,XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:17.689216Z",
     "start_time": "2021-05-12T15:28:15.831944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Fit and Evaluate single tree\n",
    "xgg_clf = XGBClassifier()\n",
    "xgg_clf.fit(X_train_df, y_train)\n",
    "evaluate_classification(xgg_clf,X_test_df,y_test,X_train=X_train_df,y_train =y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:20.032600Z",
     "start_time": "2021-05-12T15:28:17.690993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## single boosted tree with smoted data\n",
    "xgg_clf = XGBClassifier()\n",
    "xgg_clf.fit(X_train_sm, y_train_sm)\n",
    "evaluate_classification(xgg_clf,X_test_df,y_test,X_train=X_train_sm,y_train =y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `XGBRFClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:22.251155Z",
     "start_time": "2021-05-12T15:28:20.034794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## fit on smoted dta\n",
    "xgb_rf = XGBRFClassifier()\n",
    "xgb_rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(xgb_rf.score(X_train_sm,y_train_sm))\n",
    "print(xgb_rf.score(X_test_df,y_test))\n",
    "\n",
    "# y_hat_test = xgb_rf.predict(X_test)\n",
    "\n",
    "# evaluate_model(y_test,y_hat_test,X_test,xgb_rf)\n",
    "evaluate_classification(xgb_rf,X_test_df,y_test,X_train=X_train_sm,y_train =y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:24.137917Z",
     "start_time": "2021-05-12T15:28:22.253282Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## setup param grid for gridsearch\n",
    "\n",
    "xgbrf_grid = {'colsample_bynode': 0.8, 'learning_rate': 1,\n",
    "              'max_depth': 5, 'num_parallel_tree': 100, \n",
    "              'objective': 'binary:logistic', 'subsample': 0.8}\n",
    "\n",
    "xrf_clf = XGBRFClassifier(**xgbrf_grid)\n",
    "xrf_clf.fit(X_train_sm,y_train_sm)\n",
    "evaluate_classification(xrf_clf,X_test_df,y_test,X_train=X_train_sm,y_train =y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## ✍️ Stacked Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- `StackingClassifier`: \n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\n",
    "- `VotingClassifier`:\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### if there's time: combine several of the best models into one meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:35:36.134488Z",
     "start_time": "2021-05-12T15:35:36.132235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier,VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## ✍️ Using Cross Validation (besides GridSearchCV) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### CV Workflow: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Train/Test split\n",
    "2. Create a model. \n",
    "3. Apply Cross Validation with the training data. \n",
    "4. Evaluate Cross validation scores:\n",
    "    - If not happy with the scores:\n",
    "        - Try different model/hyperparameters.\n",
    "    - If happy with scores/performance:\n",
    "        - Train an **individual** model (not-cv) on the **training data** and **evaluate with the test data.**\n",
    "\n",
    "        \n",
    "5. If individual model performs well on test data (isn't overfit) **and you are planning to deploy the model:** \n",
    "    - You would **re-train the model** on the **entire combined data set** (X =X_train+X_test, y=y_train+y_test) before pickling/saving the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:24.147399Z",
     "start_time": "2021-05-12T15:28:24.144934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate,cross_val_score,cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Cross validation **functions** from sklearn.model_selection:\n",
    "    - `cross_validate`: \n",
    "        - returns dict of K-fold  scores for the training data, including the training times.\n",
    "    - `cross_val_score`:\n",
    "        - returns the K-fold validation scores for the K-fold's test-splits\n",
    "        \n",
    "    - `cross_val_predict`:\n",
    "        - returns predictions from the cross validated model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:56.357141Z",
     "start_time": "2021-05-12T15:28:56.354834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Create, fit, and evaluate a vanilla DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:57.422765Z",
     "start_time": "2021-05-12T15:28:57.000055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:58.151255Z",
     "start_time": "2021-05-12T15:28:57.723091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:58.812111Z",
     "start_time": "2021-05-12T15:28:58.381051Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## cross_val_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:28:59.423145Z",
     "start_time": "2021-05-12T15:28:58.979999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## If happy with results, train an individual model and evaluate with test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:00.270931Z",
     "start_time": "2021-05-12T15:28:59.689176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## if happy with train/test split results, can re-train model on entire dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Guide on Saving Models: \n",
    "    - https://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### With `Pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:08.376920Z",
     "start_time": "2021-05-12T15:29:08.372482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:08.937829Z",
     "start_time": "2021-05-12T15:29:08.933205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loaded_s = pickle.loads(s)\n",
    "loaded_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:40.265704Z",
     "start_time": "2021-05-12T15:29:39.888753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluate_classification(loaded_s,X_tf,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### With `joblib` (sklearn's preferred method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:48.900015Z",
     "start_time": "2021-05-12T15:29:48.894662Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:49.406313Z",
     "start_time": "2021-05-12T15:29:49.400832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_jb = joblib.load('model.joblib')\n",
    "clf_jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:29:57.089214Z",
     "start_time": "2021-05-12T15:29:56.709613Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_classification(clf_jb,X_tf,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Other Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Catboost: https://catboost.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.719px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
